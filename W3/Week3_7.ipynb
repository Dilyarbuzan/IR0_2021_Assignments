{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoekmachines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by\n",
    "\n",
    "__Name__|Yavuz| en vrienden\n",
    "\n",
    "__Student id__ : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toelichting\n",
    "\n",
    "* De meeste opgaven worden automatisch nagekeken. Bij vrijwel alle opdrachten staan er een paar zichtbare tests onder de opdracht, dit is voornamelijk om te zorgen dat je de juiste type output geeft. De andere tests worden na inleveren toegevoegd aan die cell.\n",
    "\n",
    "## Voor het inleveren!\n",
    "\n",
    "* Pas niet de cellen aan, vooral niet die je niet kunt editen. Dit levert problemen op bij nakijken. Twijfel je of je per ongeluk iets hebt gewijzigd, kopieer dan bij inleveren je antwoorden naar een nieuw bestand, zodat het niet fout kan gaan.\n",
    "\n",
    "* Zorg dat de code goed runt van boven naar beneden, verifieer dat door boven in Kernel -> Restart & Run All uit te voeren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Week-3\" data-toc-modified-id=\"Week-3-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Week 3</a></span></li><li><span><a href=\"#Questions-from-Chapter-8-in-MRS\" data-toc-modified-id=\"Questions-from-Chapter-8-in-MRS-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Questions from Chapter 8 in MRS</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#8.1\" data-toc-modified-id=\"8.1-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>8.1</a></span></li><li><span><a href=\"#8.2\" data-toc-modified-id=\"8.2-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>8.2</a></span></li><li><span><a href=\"#8.3\" data-toc-modified-id=\"8.3-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>8.3</a></span></li><li><span><a href=\"#8.4\" data-toc-modified-id=\"8.4-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>8.4</a></span></li><li><span><a href=\"#8.8\" data-toc-modified-id=\"8.8-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>8.8</a></span></li><li><span><a href=\"#8.8-extra\" data-toc-modified-id=\"8.8-extra-2.0.6\"><span class=\"toc-item-num\">2.0.6&nbsp;&nbsp;</span>8.8 extra</a></span></li><li><span><a href=\"#8.9\" data-toc-modified-id=\"8.9-2.0.7\"><span class=\"toc-item-num\">2.0.7&nbsp;&nbsp;</span>8.9</a></span></li><li><span><a href=\"#8.10\" data-toc-modified-id=\"8.10-2.0.8\"><span class=\"toc-item-num\">2.0.8&nbsp;&nbsp;</span>8.10</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Evaluation-measures\" data-toc-modified-id=\"Evaluation-measures-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Evaluation measures</a></span></li><li><span><a href=\"#Precision-recall-curve\" data-toc-modified-id=\"Precision-recall-curve-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Precision recall curve</a></span></li><li><span><a href=\"#Cohen's-Kappa\" data-toc-modified-id=\"Cohen's-Kappa-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Cohen's Kappa</a></span></li><li><span><a href=\"#10.1-Creating-a-test-set\" data-toc-modified-id=\"10.1-Creating-a-test-set-3.0.4\"><span class=\"toc-item-num\">3.0.4&nbsp;&nbsp;</span>10.1 Creating a test set</a></span></li><li><span><a href=\"#10.2-Assess-search-engine-results\" data-toc-modified-id=\"10.2-Assess-search-engine-results-3.0.5\"><span class=\"toc-item-num\">3.0.5&nbsp;&nbsp;</span>10.2 Assess search engine results</a></span></li></ul></li></ul></li><li><span><a href=\"#Programming-(Inverted-Index)\" data-toc-modified-id=\"Programming-(Inverted-Index)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Programming (Inverted Index)</a></span><ul class=\"toc-item\"><li><span><a href=\"#12-Positional-inverted-index\" data-toc-modified-id=\"12-Positional-inverted-index-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>12 Positional inverted index</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36d7e1f5bd8f35d837a0d92a79995ce9",
     "grade": false,
     "grade_id": "cell-0e1219abb9e62568",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af12c8051c04438a128342ea6f2cee92",
     "grade": false,
     "grade_id": "cell-738a659fa61ddb20",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_almost_equal\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "128135c854ecdb8bf8f0f29376bc4ab5",
     "grade": false,
     "grade_id": "cell-65656d2217b99b63",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Questions from Chapter 8 in MRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1960a516c228db42ab3e6df06fa6f44",
     "grade": false,
     "grade_id": "cell-a65f837aecb68efb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.1\n",
    "An IR system returns 8 relevant documents, and 10 nonrelevant documents. There are a total of 20 relevant documents in the collection. What is the precision of the system on this search, and what is its recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b66b1d464e71d7356374e98832cb6cd0",
     "grade": false,
     "grade_id": "cell-80134f1fef5eef35",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.4444444444444444)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = 8/20     # TP / (TP + FN)\n",
    "precision = 8/18  # TP / (TP + FP)\n",
    "\n",
    "recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b4d587ae3ea201f9ce4b2e05d2d2b31",
     "grade": true,
     "grade_id": "cell-27cb4abf121eb1fe",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(precision), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d5f6a701436594eb4c2f3cb14e9841a",
     "grade": true,
     "grade_id": "cell-399797a07036b377",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(recall), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c4ed0af0704a4a084dbf1f53113c05b",
     "grade": false,
     "grade_id": "cell-d2f88cf1c913bc0d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.2\n",
    "The balanced F measure (a.k.a. $F_1$) is defined as the harmonic mean of precision and recall. What is the advantage of using the harmonic mean rather than “averaging” (using the arithmetic mean)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d30fd647abab1986d0ef62ae8ec83c18",
     "grade": true,
     "grade_id": "cell-8c15f2522a286d6f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The value of the harmonic mean is preferred because it is a good representative of the both the values of precision and recall. \n",
    "\n",
    "The arithmetic mean is closer to the highest value between precision and recall, and therefore will not give a good representative for both values, whereas the harmonic mean is closer to the lowest value of precision and recall. For example, in a case where recall is 1 and precision is closer to 0, the arithmetic mean will return a value that is higher than 0.5 while this is not reflecting the true performance. If the harmonic mean is used here, the value will be closer to the low precision value, thereby reflecting a credible performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffac5ce81d6510d57a4b6654212936ba",
     "grade": false,
     "grade_id": "cell-eed045f5e6b3ee53",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.3\n",
    "Derive the equivalence between the two formulas for F measure shown in Equation (8.5), given that $\\alpha = 1/(\\beta^2 + 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34d760e6602741ea5c8d9ec7f0dbf70f",
     "grade": true,
     "grade_id": "cell-53a0d302308961e4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$\n",
    "F = \\frac{1}{\\alpha\\frac{1}{P}+(1 - \\alpha)\\frac{1}{R}} \\quad \\text{where} \\space \\alpha= \\frac{1}{\\beta^2+1}\\\\\n",
    "F = \\frac{1}{\\frac{1}{\\beta^2+1} \\frac{1}{P}+(1 - \\frac{1}{\\beta^2+1})\\frac{1}{R}} \\\\\n",
    "F = \\frac{1}{\\frac{1}{\\beta^2+1} \\frac{1}{P}+(\\frac{\\beta^2+1}{\\beta^2+1} - \\frac{1}{\\beta^2+1})\\frac{1}{R}} \\\\\n",
    "F = \\frac{1}{\\frac{1}{\\beta^2+1} \\frac{1}{P}+(\\frac{\\beta^2}{\\beta^2+1} )\\frac{1}{R}} \\\\\n",
    "F = \\frac{1}{\\frac{1}{\\beta^2+1} (\\frac{1}{P}+\\frac{\\beta^2}{R})} \\\\\n",
    "F = \\frac{\\beta^2+1}{ (\\frac{1}{P}+\\frac{\\beta^2}{R})} \\\\\n",
    "F = \\frac{\\beta^2+1}{ (\\frac{1}{P}+\\frac{\\beta^2}{R})} \\frac{PR}{PR}\\\\\n",
    "F = \\frac{(\\beta^2+1)PR}{ (\\frac{1}{P}PR+\\frac{\\beta^2}{R}PR)} \\\\\n",
    "F = \\frac{(\\beta^2+1)PR}{ \\beta^2P + R} \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "870db5075de36f7db00aa1d0dd4a5391",
     "grade": false,
     "grade_id": "cell-2261bc4dd91291e7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.4\n",
    "What are the possible values for interpolated precision at a recall level of 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ac0f0165254c66e09b35b5135de4cc4",
     "grade": true,
     "grade_id": "cell-cb243cc0dd24310e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Interpolated precision $\\in [0,1\\rangle$\n",
    "specifically $\\left[0,\\frac{n-1}{n}\\right]$ if there are $n$ relevant documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7111842d2595c012a3cd661b5d1b7003",
     "grade": false,
     "grade_id": "cell-d7783437d76e7668",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.8\n",
    "Consider an information need for which there are 4 relevant documents in the collection. Contrast two systems run on this collection. Their top 10 results are judged for relevance as follows (the leftmost item is the top ranked search result):\n",
    "\n",
    "| System   | R for relevant, N for nonrelevant |\n",
    "|----------|:--------------------|\n",
    "| System 1 | R N R N N N N N R R |\n",
    "| System 2 | N R N N R R R N N N |\n",
    "\n",
    "1. What is the MAP of each system? Which has a higher MAP?\n",
    "2. Does this result intuitively make sense? What does it say about what is important in getting a good MAP score?\n",
    "3. What is the R-precision of each system? (Does it rank the systems the same as MAP?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b0a3edc87feea9822de168e236475db",
     "grade": false,
     "grade_id": "cell-c42b1a9a69260467",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6, 0.4928571428571428, 0.5, 0.25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. System 1 has a higher MAP\n",
    "# 2. This makes sense, because this system has more high ranked relevant documents\n",
    "#    This means it's more important to rank the first relevant results high than\n",
    "#    it is ranking the later documents high too.\n",
    "# 3. Yes, this ranks the systems the same.\n",
    "MAP_System1 = (1/4) * ((1/1) + (2/3) + (3/9) + (4/10))\n",
    "MAP_System2 = (1/4) * ((1/2) + (2/5) + (3/6) + (4/7))\n",
    "R_P_System1 = 2/4\n",
    "R_P_System2 = 1/4\n",
    "\n",
    "MAP_System1, MAP_System2, R_P_System1, R_P_System2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7068ae217f1658d8f06112e3e40fa774",
     "grade": true,
     "grade_id": "cell-2c0a902081d76545",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(MAP_System1), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "633b3e964c4aa9a772bc873bf010aeb5",
     "grade": true,
     "grade_id": "cell-084f6e73ce2878f5",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(MAP_System2), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bc2ffe084a1acc42ab121385a18f7da",
     "grade": true,
     "grade_id": "cell-9614d1b2e6815021",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(R_P_System1), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "858ea4d21f32f7db0eb4d7aec019f611",
     "grade": true,
     "grade_id": "cell-c8aefed6b2b8398e",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(R_P_System2), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "773a7d83f5998b44de6f0af2d35ed94f",
     "grade": false,
     "grade_id": "88v",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.8 extra\n",
    "\n",
    "1. On the same data is used in the previous exercise, what would the MAP be when there would be 10 relevant documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75df7a1552351d14bc2a622f20081d00",
     "grade": false,
     "grade_id": "88a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MAP_System1ex = (1/10) * ((1/1) + (2/3) + (3/9) + (4/10)) \n",
    "MAP_System2ex = (1/10) * ((1/2) + (2/5) + (3/6) + (4/7)) \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "125540b05112f0e8ecea9458fa616f70",
     "grade": true,
     "grade_id": "88t",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(MAP_System1ex), float)\n",
    "assert_equal(type(MAP_System2ex), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "145183e2b1ba270789d3a8f18cb14e85",
     "grade": false,
     "grade_id": "cell-1f877ea183d14013",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.9\n",
    "\n",
    "The following list of Rs and Ns represents relevant (R) and nonrelevant (N) returned documents in a ranked list of 20 documents retrieved in response to a query from a collection of 10,000 documents. The top of the ranked list (the document the system thinks is most likely to be relevant) is on the left of the list. This list shows 6 relevant documents. Assume that there are 8 relevant documents in total in the collection.\n",
    "\n",
    " > R R N N N $\\quad$ N N N R N $\\quad$ R N N N R $\\quad$ N N N N R\n",
    "\n",
    "1. What is the precision of the system on the top 20? (variable `precision`)\n",
    "2. What is the F1 on the top 20? (variable `F1`)\n",
    "3. What is the uninterpolated precision of the system at 25% recall? (variable `uninterpolated`)\n",
    "4. What is the interpolated precision at 33% recall? (variable `interpolated`)\n",
    "5. Assume that these 20 documents are the complete result set of the system. What is the AP for the query?<br/><br/>\n",
    "Assume, now, instead, that the system returned the entire 10,000 documents in a ranked list, and these are the first 20 results returned.<br/><br/>\n",
    "6. What is the largest possible AP that this system could have? (variable `largest_AP`)\n",
    "7. What is the smallest possible AP that this system could have? (variable `smallest_AP`)\n",
    "8. In a set of experiments, only the top 20 results are evaluated by hand. The result in (e) is used to approximate the range (f)–(g). For this example, how large (in absolute terms) can the error for the AP be by calculating (e) instead of (f) and (g) for this query? (variable `Error`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15b06a1b04586c07b10c9cda022f8c03",
     "grade": false,
     "grade_id": "cell-6ececd8d73bfc0ca",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3,\n",
       " 0.4285714285714285,\n",
       " 1.0,\n",
       " 0.36363636363636365,\n",
       " 0.555050505050505,\n",
       " 0.5034090909090909,\n",
       " 0.4164753875387539,\n",
       " 0.1385751175117511)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 6/20\n",
    "F1 = (2 * precision * (6/8)) / (precision + (6/8)) \n",
    "uninterpolated = 2 / 2   # 25% of 8 is 2, first two documents are both relevant\n",
    "interpolated = max(3/9, 4/11, 5/15, 6/20)  #  ->  4/11\n",
    "AP_query = (1/6) * ((1/1) + (2/2) + (3/9) + (4/11) + (5/15) + (6/20))\n",
    "largest_AP = (1/8) * ((1/1) + (2/2) + (3/9) + (4/11) + (5/15) + (6/20) + (7/21) + (8/22))\n",
    "smallest_AP = (1/8) * ((1/1) + (2/2) + (3/9) + (4/11) + (5/15) + (6/20) + (7/9999) + (8/10000))\n",
    "Error = max(AP_query - largest_AP, AP_query - smallest_AP)\n",
    "\n",
    "precision, F1, uninterpolated, interpolated, AP_query, largest_AP, smallest_AP, Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "692448c0d136e60c5ced6e3abe8f4fd3",
     "grade": true,
     "grade_id": "cell-c2bb032e00c4dee1",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(precision) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d4b52d8e67f79a97cf5bf0a5f0b59ed",
     "grade": true,
     "grade_id": "cell-464b3522aa196af7",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(F1) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "217d3651897af1c4b8fbee04ce310b18",
     "grade": true,
     "grade_id": "cell-ee2af88f21b18a7d",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(uninterpolated) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daf0f299ac6ecc5f7545a662cbd9e16a",
     "grade": true,
     "grade_id": "cell-ee2af88f21b18a7dex",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(interpolated) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5d6fe375a8f2dec0a947b37f066af0b",
     "grade": true,
     "grade_id": "cell-dd18f398ad9a11ea",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(AP_query) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d4a9d3e1f376f843680fb044f6f79b5",
     "grade": true,
     "grade_id": "cell-43dee696647831ac",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(largest_AP) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eeae02e405950f380a48bdecbdc7a06d",
     "grade": true,
     "grade_id": "cell-6efcd2c3d9ed173c",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(smallest_AP) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d437ef9bd15ea427fc681b643afb534",
     "grade": true,
     "grade_id": "cell-dcd93ad480d010ac",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(Error) in [float,int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3aef48cb18e14805cdb8213df5707eee",
     "grade": false,
     "grade_id": "cell-653e5c66190845a3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.10\n",
    "Below is a table showing how two human judges rated the relevance of a set of 12 documents to a particular information need (0 = nonrelevant, 1 = relevant). Let us assume that you’ve written an IR system that for this query returns the set of documents {4, 5, 6, 7, 8}\n",
    "\n",
    "| docId | Judge 1 | Judge 2|\n",
    "|------:|:--------|:-------|\n",
    "| 1     | 0       | 0      |\n",
    "| 2     | 0       | 0      |\n",
    "| 3     | 1       | 1      |\n",
    "| 4     | 1       | 1      |\n",
    "| 5     | 1       | 0      |\n",
    "| 6     | 1       | 0      |\n",
    "| 7     | 1       | 0      |\n",
    "| 8     | 1       | 0      |\n",
    "| 9     | 0       | 1      |\n",
    "| 10    | 0       | 1      |\n",
    "| 11    | 0       | 1      |\n",
    "| 12    | 0       | 1      |\n",
    "\n",
    "1. Calculate the kappa measure between the two judges.\n",
    "2. Calculate precision, recall, and F1 of your system if a document is considered relevant only if the two judges agree.\n",
    "3. Calculate precision, recall, and F1 of your system if a document is considered relevant if either judge thinks it is relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb4c1b27e6776637331d142902b8ccac",
     "grade": false,
     "grade_id": "cell-72efecf88879db26",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.33333333333333337\n",
      "0.2 0.5 0.28571428571428575\n",
      "1.0 0.5 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "Pr = (6+6) / (12+12)\n",
    "Pnr = (6+6) / (12+12)\n",
    "Pchance = Pr * Pr + Pnr * Pnr\n",
    "kappa = ((4/12) - (Pchance)) /  (1 - (Pchance))\n",
    "\n",
    "# if the two judges agree.\n",
    "precision1 =  1/5\n",
    "recall1 =  1/2\n",
    "F1score1 = (2 * precision1 * recall1) / (precision1 + recall1) \n",
    "\n",
    "# if either judge thinks it is relevant.\n",
    "precision2 = 5/5\n",
    "recall2 = 5/10\n",
    "F1score2 = (2 * precision2 * recall2) / (precision2 + recall2) \n",
    "\n",
    "\n",
    "print(kappa)\n",
    "print(precision1, recall1, F1score1)\n",
    "print(precision2, recall2, F1score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad86d4c9429ec0ee3fe6b13676b9c72c",
     "grade": true,
     "grade_id": "cell-d0b49ee6b738d816",
     "locked": true,
     "points": 0.33,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(kappa) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "627faf4e76f87e5cb92feb67972bb9fa",
     "grade": true,
     "grade_id": "cell-6c4430b58ad99642",
     "locked": true,
     "points": 0.33,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(precision1) in [float,int]\n",
    "assert type(recall1) in [float,int]\n",
    "assert type(F1score1) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df6af0266e84e0a9a1d839637e6bba72",
     "grade": true,
     "grade_id": "cell-b4ddeb8ad1122e7e",
     "locked": true,
     "points": 0.34,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(precision2) in [float,int]\n",
    "assert type(recall2) in [float,int]\n",
    "assert type(F1score2) in [float,int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "278dc547a0840b2625d16df9ef63fd62",
     "grade": false,
     "grade_id": "cell-db608e43be498940",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28898816090b94a56863e26251744777",
     "grade": false,
     "grade_id": "em-v",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Evaluation measures\n",
    "\n",
    "1. Define a function `Rprecision(ranked_list_of_results,list_of_relevant_objects)` which does what it says, it returns the R-precision given the input data.\n",
    "2. Define a function `AveragePrecision(ranked_list_of_results,list_of_relevant_objects)` which returns the average precision of this list of results given the list of relevant answers.\n",
    "\n",
    "Both functions of course come with one or two well chosen tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de18476927f4ff49054c47b24b947ed4",
     "grade": false,
     "grade_id": "em-a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.6\n"
     ]
    }
   ],
   "source": [
    "# Here you can add helper functions if needed or handy\n",
    "\n",
    "\n",
    "\n",
    "def Rprecision(ranked_list_of_results,list_of_relevant_objects):\n",
    "    totalRelevant = len(list_of_relevant_objects)\n",
    "\n",
    "    listranked = min(len(ranked_list_of_results), totalRelevant)\n",
    "    rel = 0\n",
    "    for i in range(listranked):\n",
    "        if ranked_list_of_results[i] in list_of_relevant_objects:\n",
    "            rel += 1\n",
    "            \n",
    "    return rel / totalRelevant\n",
    "\n",
    "    \n",
    "def AveragePrecision(ranked_list_of_results, list_of_relevant_objects):\n",
    "    rel = 0\n",
    "    AP = 0\n",
    "    \n",
    "    for i, result in enumerate(ranked_list_of_results, 1):\n",
    "        if result in list_of_relevant_objects:\n",
    "            rel += 1\n",
    "            AP += rel / (i)\n",
    "    \n",
    "    return AP / rel\n",
    "\n",
    "# Hint Define a couple of good tests \n",
    "print(Rprecision([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 3, 9, 10]))\n",
    "print(AveragePrecision([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], [1, 3, 9, 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9191f5774f4535d104d1fe42ae7b5db9",
     "grade": true,
     "grade_id": "em-t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(Rprecision([1], [1]), float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d05f65deb46ae4ba034726c7805266c",
     "grade": true,
     "grade_id": "em-t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(AveragePrecision([1], [1]), float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcac3e11641ce8c14ae19db88da51fc4",
     "grade": false,
     "grade_id": "pr",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Precision recall curve\n",
    "\n",
    "We create the interpolated precision-recall curve as in Figure 8.2 in MRS for one topic. We use for this the file \n",
    "`qrels.robust2004.txt`.\n",
    "\n",
    "It is easy to read in your data using pandas. We give some code to get you started.\n",
    "\n",
    "Store your answer in the dict `PR` using the provided schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46211e4c53a958b9fba1b3e925b1e6a6",
     "grade": false,
     "grade_id": "prc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP: topic 301 0.2762523813333312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPIC</th>\n",
       "      <th>ITERATION</th>\n",
       "      <th>DOCUMENT_ID</th>\n",
       "      <th>RELEVANCY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOPIC  ITERATION  DOCUMENT_ID  RELEVANCY\n",
       "0    301          0  FBIS3-10082          1\n",
       "1    301          0  FBIS3-10169          0\n",
       "2    301          0  FBIS3-10243          1\n",
       "3    301          0  FBIS3-10319          0\n",
       "4    301          0  FBIS3-10397          1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels= pd.read_csv('qrels.robust2004.txt', sep=' ', header=None, \n",
    "                   names=['TOPIC',      'ITERATION',      'DOCUMENT_ID',     'RELEVANCY'])# https://trec.nist.gov/data/robust/qrels.robust2004.txt\n",
    "\n",
    "\n",
    "# Create Figure8\n",
    "\n",
    "rankedlist= qrels[(qrels.TOPIC==301)].DOCUMENT_ID.unique()\n",
    "np.random.shuffle(rankedlist) # This causes that the PR curve is different all the time (and often quite weird)\n",
    "relevantdocs=set(qrels[(qrels.TOPIC==301)&(qrels.RELEVANCY==1)].DOCUMENT_ID.unique() )\n",
    "\n",
    "N= len(relevantdocs)\n",
    "Rlevels=[(r+1) /N for r in range(len(relevantdocs))] \n",
    "\n",
    "print('AP: topic 301', AveragePrecision(rankedlist,relevantdocs  ))\n",
    "\n",
    "qrels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01027c61279685324d810cc33e4b7e55",
     "grade": false,
     "grade_id": "pra",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Figure8.2 for topic 301\n",
    "# You must calculate the correct precison values for every given recall value here\n",
    "# Create boolean list in order of rankedlist indicating which docs are relevant\n",
    "rankeddocisrelevant = np.array([doc in relevantdocs for doc in rankedlist])\n",
    "# r * N is relevant documents at recall level r\n",
    "# rankeddocisrelevant.cumsum() is list of total relevant docs seen, also for docs that aren't relevant\n",
    "# cumsum / N <= r is list of such that all indices that have a lower recall than r are True\n",
    "# .sum() calculates the index of the r*N-th relevant document, AKA True Positives and False Positives combined\n",
    "PR={'UninterpolatedP':{r: r*N / (rankeddocisrelevant.cumsum() / N <= r).sum() for r in Rlevels}}\n",
    "# Relatively efficient creation of interpolated line, because we don't recalculate precisions\n",
    "#   We work from recall 1 back to recall 0.  Thus we can compare the highest so far with the\n",
    "#   current precision and take the largest of these two.\n",
    "prevInterpolated = PR['UninterpolatedP'][Rlevels[-1]]\n",
    "PRinterpolatedP = {Rlevels[-1]: prevInterpolated}\n",
    "for r in Rlevels[-2::-1]:\n",
    "    prevInterpolated = max(PR['UninterpolatedP'][r], prevInterpolated)\n",
    "    PRinterpolatedP[r] = prevInterpolated\n",
    "# Create in a local dict first so we don't keep indexing PR['InterpolatedP'], which'd slow things down\n",
    "PR['InterpolatedP'] = PRinterpolatedP\n",
    "\n",
    "\n",
    "pd.DataFrame(PR).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "326d67024d102de958f6dab1f96d765f",
     "grade": true,
     "grade_id": "prt",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert set(PR.keys())=={'UninterpolatedP', 'InterpolatedP'}\n",
    "for K in PR:\n",
    "     assert isinstance(PR[K],dict)\n",
    "assert_equal(set(PR['UninterpolatedP'].keys()),set(Rlevels))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d409e7643408910bcf2f768c2df01899",
     "grade": false,
     "grade_id": "ck-v",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Cohen's Kappa\n",
    "\n",
    "Compute the chance $P(E)$ used in the calculation of Cohen's Kappa, using the pooled marginals method.\n",
    "\n",
    "Your data looks like that given in Exercise 8.10: An array of pairs with binary relevance judgements in which the first column contains the scores of the first judge, etc.\n",
    "\n",
    "Hint: `numpy` arrays have all kind of handy methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4416d9b5b37301b3a183748753f90b7",
     "grade": false,
     "grade_id": "ck-a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input data size of kappa must be like this\n",
    "data= np.array([[1,1],[1,0],[0,1],[1,1],[0,0]])\n",
    "\n",
    "def PE(data):\n",
    "    '''On input `data`, return the   P(E) (expected agreement).'''\n",
    "     \n",
    "    data = np.array(data)\n",
    "    j_1 = data[:,0]\n",
    "    j_2 = data[:,1]\n",
    "    Pr = np.count_nonzero(np.equal(j_1, 0)) + np.count_nonzero(np.equal(j_2, 0))\n",
    "    Pnr = np.count_nonzero(np.equal(j_1, 1)) + np.count_nonzero(np.equal(j_2, 1))\n",
    "    P_E = (Pr/data.size)**2 + (Pnr/data.size)**2\n",
    "    return P_E \n",
    "\n",
    "PE(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cf21d47e9b7070cf58716b8627b85aa",
     "grade": true,
     "grade_id": "ck-t",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(PE(data), float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "627ad98ff8f230481ad539fd36a2df43",
     "grade": false,
     "grade_id": "cell-891a3bbce2d771fa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 10.1 Creating a test set\n",
    "\n",
    "Create a test collection in order to evaluate your two search engines (cosine similarity and BM25) on the set of Shakespeare. Create five information needs, which you express as queries. Use multi term queries only. For each information need you specify\n",
    "\n",
    " * The information need in natural language\n",
    " * The search query\n",
    " * A description when a document is considered relevant and when it is not. This should be a very clear description. A person assessing relevance may only use this together with the information need to determine relevance of a document. In particular the judge should not see the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52040542d5f6c5c6fea8d35ad4a1ffb5",
     "grade": true,
     "grade_id": "cell-3fd2c07428004c67",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "1. Which plays contains animals?\n",
    "Query: animal, carnal, pet, creature, beast\n",
    "\n",
    "A document is relevant when there is an animal mentioned in the play. \n",
    "\n",
    "2. Which plays are about family?\n",
    "Query: family, household, folk, father, mother\n",
    "\n",
    "A document is relevant when there is a family relationship\n",
    "\n",
    "3. Which plays take place in multiple countries?\n",
    "Query: country, international, nation, overseas\n",
    "\n",
    "A document is relevant when at least 3 scenes of the play take part in a different country than the main place of recidence.\n",
    "\n",
    "4. Which play contains a time skip?\n",
    "years later, months later, backflash\n",
    "\n",
    "A document is relevant when a large part of the lives of one of the main characters is glossed over.\n",
    "Before and after this time the play should continue as normal, making the people watching wonder what happened during that time.\n",
    "\n",
    "---\n",
    "\n",
    "In the _werkcollege_ we got one solution, which was something like:\n",
    "\n",
    "5. All documents which contain information about the Roman Empire.\n",
    "\n",
    "Query: roman AND empire\n",
    "\n",
    "All plays which take place in full or in part in the Roman Empire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16f16b8c95fcffd6029b5cfde151fa75",
     "grade": false,
     "grade_id": "cell-1af8400eea1e3e8e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 10.2 Assess search engine results\n",
    "\n",
    "Assess for your two search engines, for all five information needs the first 10 results given back by the systems. Let another student do the same task as well.\n",
    "1. Using your own relevance judgments, compute for each system, the precision at 10 for each query, and the average P@10. Discuss the results.\n",
    "2. You have now two times at least 50 relevance judgements, and probably more. Compute the kappa measure between the two judges as in exercise 8.10, using pooled marginals as in Table 8.2. Discuss your results and try to explain them.\n",
    "3. Now compute P@10 for both systems again, once using the relevance judgments of the other assessor, once in which you say that a document is relevant if BOTH judges said it was relevant, and once in which you say that a document is relevant if AT LEAST ONE of the judges said it was relevant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "668cb299c87264fda9c0bb50078702d1",
     "grade": true,
     "grade_id": "cell-1f5104381710e6d4",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64b042a414ab4186ff36da8de10fc0ca",
     "grade": false,
     "grade_id": "cell-0828c47c6c841ab2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Programming (Inverted Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45265903cced267bded49289c1a33748",
     "grade": false,
     "grade_id": "cell-ee70e59824b4530f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def loadShakespeare():\n",
    "    if 'shaks200.zip' in os.listdir():\n",
    "        return 'shaks200.zip'\n",
    "    elif os.path.exists('../../data/Week3/'):\n",
    "        return '../../data/Week3/shaks200.zip'\n",
    "    elif os.path.exists('../../../data/Week3/'):\n",
    "        return '../../../data/Week3/shaks200.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a291330f776161fa4f004ba6e02d511",
     "grade": false,
     "grade_id": "cell-2cd22bbe0ed6e5b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 12 Positional inverted index\n",
    "Adjust your software making an inverted index for the Shakespeare collection: the output should be a positional index. A positional index is an index that also stores the position of the occurrences of a word in a document. The following figure shows an example of a positional index.\n",
    "\n",
    "<img src=\"http://nlp.stanford.edu/IR-book/html/htmledition/img121.png\" />\n",
    "\n",
    "Make the index of the form (defaultdicts are also allowed!):\n",
    "```\n",
    "{'caesar':   {'files': \n",
    "                 {'lll': {'list': [25350], 'total': 1},\n",
    "                  'm_for_m': {'list': [6773, 14734], 'total': 2},\n",
    "                  'm_wives': {'list': [3459], 'total': 1},\n",
    "                  'macbeth': {'list': [9256], 'total': 1},\n",
    "                  'othello': {'list': [11728], 'total': 1},\n",
    "                  'rich_ii': {'list': [22695], 'total': 1},\n",
    "                  'rich_iii': {'list': [16418, 16570, 30799, 30801], 'total': 4},\n",
    "                  'titus': {'list': [368], 'total': 1},\n",
    "                  ....\n",
    "                  },\n",
    "               'total': 604}....\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d6c8aae378a5c4105975e2845550b86",
     "grade": true,
     "grade_id": "cell-498f786fcde3299d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zirk/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d45128c0ae42ff852b9b0564944cbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'files': defaultdict(<function __main__.positional_inverted_index.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "             {'a_and_c': {'list': [18061, 26172], 'total': 2},\n",
       "              'all_well': {'list': [7885, 19143], 'total': 2},\n",
       "              'as_you': {'list': [7684], 'total': 1},\n",
       "              'com_err': {'list': [5025, 5043, 5371, 5410, 5751, 7244, 11048],\n",
       "               'total': 7},\n",
       "              'coriolan': {'list': [7308, 7584, 20069], 'total': 3},\n",
       "              'cymbelin': {'list': [2075, 6858], 'total': 2},\n",
       "              'dream': {'list': [7147,\n",
       "                7299,\n",
       "                8022,\n",
       "                8159,\n",
       "                11847,\n",
       "                12275,\n",
       "                13316,\n",
       "                16258],\n",
       "               'total': 8},\n",
       "              'hamlet': {'list': [11356, 12798, 26461, 26640], 'total': 4},\n",
       "              'hen_iv_2': {'list': [5752, 7687], 'total': 2},\n",
       "              'hen_v': {'list': [9477, 15296, 15317], 'total': 3},\n",
       "              'j_caesar': {'list': [14444, 14485], 'total': 2},\n",
       "              'john': {'list': [3672, 3674], 'total': 2},\n",
       "              'lear': {'list': [5742, 6249], 'total': 2},\n",
       "              'lll': {'list': [6524, 6541, 20384, 20409], 'total': 4},\n",
       "              'm_for_m': {'list': [9564, 22645], 'total': 2},\n",
       "              'm_wives': {'list': [1436, 9221, 9224, 22315], 'total': 4},\n",
       "              'much_ado': {'list': [17288,\n",
       "                17292,\n",
       "                17316,\n",
       "                17324,\n",
       "                17338,\n",
       "                17433,\n",
       "                19562,\n",
       "                19967],\n",
       "               'total': 8},\n",
       "              'othello': {'list': [509, 8566], 'total': 2},\n",
       "              'rich_ii': {'list': [23037], 'total': 1},\n",
       "              't_night': {'list': [1565,\n",
       "                6001,\n",
       "                7042,\n",
       "                7228,\n",
       "                7230,\n",
       "                11581,\n",
       "                17975,\n",
       "                17987],\n",
       "               'total': 8},\n",
       "              'taming': {'list': [5926, 10513, 13037, 19683], 'total': 4},\n",
       "              'tempest': {'list': [16876], 'total': 1},\n",
       "              'timon': {'list': [2341, 9810, 14832, 14837, 15003], 'total': 5},\n",
       "              'titus': {'list': [13439], 'total': 1},\n",
       "              'troilus': {'list': [6913, 16521, 22345, 22351, 22364, 25330],\n",
       "               'total': 6},\n",
       "              'two_gent': {'list': [5122, 7140, 7293, 16326], 'total': 4}}),\n",
       " 'total': 90}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def positional_inverted_index(zipfolder):\n",
    "    # With zipfile we can read the file without opening the zip file\n",
    "    archive = zipfile.ZipFile(zipfolder, 'r')\n",
    "    namelist = [x for x in archive.namelist() if '.xml' in x]\n",
    "    \n",
    "    # index is of the form:\n",
    "    positional_index = defaultdict(lambda: {\n",
    "        'files': defaultdict(lambda:\n",
    "            {'list': [], 'total': 0}\n",
    "        ),\n",
    "        'total': 0\n",
    "    })\n",
    "    \n",
    "    # loop over each file\n",
    "    for infile in tqdm_notebook(namelist):\n",
    "        # strip .xml from file names\n",
    "        play_name = infile[:-4]\n",
    "        # Use a context so the file is automatically closed\n",
    "        with archive.open(infile) as f:\n",
    "            soup = BeautifulSoup(f, 'xml')\n",
    "            text = soup.get_text()\n",
    "            index = 0\n",
    "            for token in nltk.tokenize.word_tokenize(text):\n",
    "                # Skip non-alphabetic and empty tokens\n",
    "                if not (token.isalpha() and token):\n",
    "                    continue\n",
    "                # Ignore position of skipped tokens, start counting at 1\n",
    "                index += 1\n",
    "                \n",
    "                # casefold is a more aggressive lowercase method\n",
    "                token = token.casefold()\n",
    "                \n",
    "                # Store dicts in temp variables to avoid double indexing\n",
    "                token_index = positional_index[token]\n",
    "                token_in_play = token_index['files'][play_name]\n",
    "                token_in_play['list'].append(index)\n",
    "                token_in_play['total'] += 1\n",
    "                token_index['total'] += 1\n",
    "                \n",
    "    return positional_index\n",
    "\n",
    "\n",
    "positional_index = positional_inverted_index(loadShakespeare())\n",
    "positional_index['ass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6e21d8ffeb36779f0b33421a0797a57",
     "grade": true,
     "grade_id": "cell-29881806b7e5b184",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zirk/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90da4d87fc94a24b730631b1e5064b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positional_index = positional_inverted_index(loadShakespeare())\n",
    "assert type(positional_index) in [dict, defaultdict]\n",
    "assert_equal(set(positional_index['the'].keys()), {'total','files'})\n",
    "assert_equal(type(positional_index['the']['total']), int)\n",
    "assert_equal(set(positional_index['the']['files']['lll'].keys()), {'total','list'})\n",
    "assert_equal(type(positional_index['the']['files']['lll']['list']), list)\n",
    "assert_equal(type(positional_index['the']['files']['lll']['total']), int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
