{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zoekmachines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook made by\n",
    "\n",
    "__Name__|Jan| en vrienden\n",
    "\n",
    "__Student id__ : secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toelichting\n",
    "\n",
    "* De meeste opgaven worden automatisch nagekeken. Bij vrijwel alle opdrachten staan er een paar zichtbare tests onder de opdracht, dit is voornamelijk om te zorgen dat je de juiste type output geeft. De andere tests worden na inleveren toegevoegd aan die cell.\n",
    "\n",
    "## Voor het inleveren!\n",
    "\n",
    "* Pas niet de cellen aan, vooral niet die je niet kunt editen. Dit levert problemen op bij nakijken. Twijfel je of je per ongeluk iets hebt gewijzigd, kopieer dan bij inleveren je antwoorden naar een nieuw bestand, zodat het niet fout kan gaan.\n",
    "\n",
    "* Zorg dat de code goed runt van boven naar beneden, verifieer dat door boven in Kernel -> Restart & Run All uit te voeren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Week-3\" data-toc-modified-id=\"Week-3-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Week 3</a></span></li><li><span><a href=\"#Questions-from-Chapter-8-in-MRS\" data-toc-modified-id=\"Questions-from-Chapter-8-in-MRS-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Questions from Chapter 8 in MRS</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#8.1\" data-toc-modified-id=\"8.1-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>8.1</a></span></li><li><span><a href=\"#8.2\" data-toc-modified-id=\"8.2-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>8.2</a></span></li><li><span><a href=\"#8.3\" data-toc-modified-id=\"8.3-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>8.3</a></span></li><li><span><a href=\"#8.4\" data-toc-modified-id=\"8.4-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>8.4</a></span></li><li><span><a href=\"#8.8\" data-toc-modified-id=\"8.8-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>8.8</a></span></li><li><span><a href=\"#8.8-extra\" data-toc-modified-id=\"8.8-extra-2.0.6\"><span class=\"toc-item-num\">2.0.6&nbsp;&nbsp;</span>8.8 extra</a></span></li><li><span><a href=\"#8.9\" data-toc-modified-id=\"8.9-2.0.7\"><span class=\"toc-item-num\">2.0.7&nbsp;&nbsp;</span>8.9</a></span></li><li><span><a href=\"#8.10\" data-toc-modified-id=\"8.10-2.0.8\"><span class=\"toc-item-num\">2.0.8&nbsp;&nbsp;</span>8.10</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Evaluation-measures\" data-toc-modified-id=\"Evaluation-measures-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Evaluation measures</a></span></li><li><span><a href=\"#Precision-recall-curve\" data-toc-modified-id=\"Precision-recall-curve-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Precision recall curve</a></span></li><li><span><a href=\"#Cohen's-Kappa\" data-toc-modified-id=\"Cohen's-Kappa-3.0.3\"><span class=\"toc-item-num\">3.0.3&nbsp;&nbsp;</span>Cohen's Kappa</a></span></li><li><span><a href=\"#10.1-Creating-a-test-set\" data-toc-modified-id=\"10.1-Creating-a-test-set-3.0.4\"><span class=\"toc-item-num\">3.0.4&nbsp;&nbsp;</span>10.1 Creating a test set</a></span></li><li><span><a href=\"#10.2-Assess-search-engine-results\" data-toc-modified-id=\"10.2-Assess-search-engine-results-3.0.5\"><span class=\"toc-item-num\">3.0.5&nbsp;&nbsp;</span>10.2 Assess search engine results</a></span></li></ul></li></ul></li><li><span><a href=\"#Programming-(Inverted-Index)\" data-toc-modified-id=\"Programming-(Inverted-Index)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Programming (Inverted Index)</a></span><ul class=\"toc-item\"><li><span><a href=\"#12-Positional-inverted-index\" data-toc-modified-id=\"12-Positional-inverted-index-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>12 Positional inverted index</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36d7e1f5bd8f35d837a0d92a79995ce9",
     "grade": false,
     "grade_id": "cell-0e1219abb9e62568",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af12c8051c04438a128342ea6f2cee92",
     "grade": false,
     "grade_id": "cell-738a659fa61ddb20",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_almost_equal\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "import nltk\n",
    "from collections import Counter, defaultdict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "128135c854ecdb8bf8f0f29376bc4ab5",
     "grade": false,
     "grade_id": "cell-65656d2217b99b63",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Questions from Chapter 8 in MRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1960a516c228db42ab3e6df06fa6f44",
     "grade": false,
     "grade_id": "cell-a65f837aecb68efb",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.1\n",
    "An IR system returns 8 relevant documents, and 10 nonrelevant documents. There are a total of 20 relevant documents in the collection. What is the precision of the system on this search, and what is its recall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b66b1d464e71d7356374e98832cb6cd0",
     "grade": false,
     "grade_id": "cell-80134f1fef5eef35",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.4444444444444444)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = 8/20\n",
    "precision = 8/18\n",
    "\n",
    "recall, precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6b4d587ae3ea201f9ce4b2e05d2d2b31",
     "grade": true,
     "grade_id": "cell-27cb4abf121eb1fe",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(precision), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d5f6a701436594eb4c2f3cb14e9841a",
     "grade": true,
     "grade_id": "cell-399797a07036b377",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(recall), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c4ed0af0704a4a084dbf1f53113c05b",
     "grade": false,
     "grade_id": "cell-d2f88cf1c913bc0d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.2\n",
    "The balanced F measure (a.k.a. $F_1$) is defined as the harmonic mean of precision and recall. What is the advantage of using the harmonic mean rather than “averaging” (using the arithmetic mean)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d30fd647abab1986d0ef62ae8ec83c18",
     "grade": true,
     "grade_id": "cell-8c15f2522a286d6f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "### ANSWER: With the arithmetic mean you can always achieve a score of 50% by just returning all documents, since the recall will always be 100%.\n",
    "\n",
    "### When you use the harmonic mean the score will be scaled by the low precision value. So if either the precision or recall is extremely low to harmonic mean will be way lower than 50%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffac5ce81d6510d57a4b6654212936ba",
     "grade": false,
     "grade_id": "cell-eed045f5e6b3ee53",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.3\n",
    "Derive the equivalence between the two formulas for F measure shown in Equation (8.5), given that $\\alpha = 1/(\\beta^2 + 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "34d760e6602741ea5c8d9ec7f0dbf70f",
     "grade": true,
     "grade_id": "cell-53a0d302308961e4",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$$\\frac{1}{\\alpha \\frac{1}{P} + (1 - \\alpha) \\frac{1}{R}}$$\n",
    "\n",
    "$$\\frac{(\\beta^2 + 1)PR}{\\beta^2p + R}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "870db5075de36f7db00aa1d0dd4a5391",
     "grade": false,
     "grade_id": "cell-2261bc4dd91291e7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.4\n",
    "What are the possible values for interpolated precision at a recall level of 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5ac0f0165254c66e09b35b5135de4cc4",
     "grade": true,
     "grade_id": "cell-cb243cc0dd24310e",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "$$0< interpolatedprecision \\leq 1$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7111842d2595c012a3cd661b5d1b7003",
     "grade": false,
     "grade_id": "cell-d7783437d76e7668",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.8\n",
    "Consider an information need for which there are 4 relevant documents in the collection. Contrast two systems run on this collection. Their top 10 results are judged for relevance as follows (the leftmost item is the top ranked search result):\n",
    "\n",
    "| System   | R for relevant, N for nonrelevant |\n",
    "|----------|:--------------------|\n",
    "| System 1 | R N R N N N N N R R |\n",
    "| System 2 | N R N N R R R N N N |\n",
    "\n",
    "1. What is the MAP of each system? Which has a higher MAP?\n",
    "2. Does this result intuitively make sense? What does it say about what is important in getting a good MAP score?\n",
    "3. What is the R-precision of each system? (Does it rank the systems the same as MAP?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System 1 MAP: 2.4\n",
      "System 1 MAP: 1.9714285714285713\n",
      "System 1 has a higher MAP \n",
      "\n",
      "\n",
      "No this does not make sense. I would think System 1 has a higher MAP since\n",
      "System 2 retrieves all relevant docs within 7 hits whereas System 1 needs 10 hits.\n",
      "This tells us that the MAP weights the first precision values higher than later precision values.\n",
      "\n",
      "\n",
      "System 1 R precision: 0.5\n",
      "System 2 R precision: 0.25\n",
      "No it does not rank the systems the same as MAP but it does correlate as you can tell that the system with the \n",
      "higher also has a higher R precision.\n"
     ]
    }
   ],
   "source": [
    "### Answer:\n",
    "### 1\n",
    "MAP_s1 = 1+2/3+3/9+4/10\n",
    "MAP_s2 = 1/2+2/5+3/6+4/7\n",
    "print('System 1 MAP: {}'.format(MAP_s1))\n",
    "print('System 1 MAP: {}'.format(MAP_s2))\n",
    "print('System 1 has a higher MAP \\n\\n')\n",
    "\n",
    "### 2\n",
    "print('No this does not make sense. I would think System 1 has a higher MAP since') \n",
    "print('System 2 retrieves all relevant docs within 7 hits whereas System 1 needs 10 hits.')\n",
    "print('This tells us that the MAP weights the first precision values higher than later precision values.')\n",
    "\n",
    "### 3\n",
    "R_prec1 = 2/4\n",
    "R_prec2 = 1/4\n",
    "print('\\n\\nSystem 1 R precision: {}'.format(R_prec1))\n",
    "print('System 2 R precision: {}'.format(R_prec2))\n",
    "print('No it does not rank the systems the same as MAP but it does correlate as you can tell that the system with the ')\n",
    "print('higher also has a higher R precision.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b0a3edc87feea9822de168e236475db",
     "grade": false,
     "grade_id": "cell-c42b1a9a69260467",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4, 1.9714285714285713, 0.5, 0.25)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAP_System1 = 1+2/3+3/9+4/10\n",
    "MAP_System2 = 1/2+2/5+3/6+4/7\n",
    "R_P_System1 = 2/4\n",
    "R_P_System2 = 1/4\n",
    "\n",
    "MAP_System1, MAP_System2, R_P_System1, R_P_System2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7068ae217f1658d8f06112e3e40fa774",
     "grade": true,
     "grade_id": "cell-2c0a902081d76545",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(MAP_System1), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "633b3e964c4aa9a772bc873bf010aeb5",
     "grade": true,
     "grade_id": "cell-084f6e73ce2878f5",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(MAP_System2), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bc2ffe084a1acc42ab121385a18f7da",
     "grade": true,
     "grade_id": "cell-9614d1b2e6815021",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(R_P_System1), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "858ea4d21f32f7db0eb4d7aec019f611",
     "grade": true,
     "grade_id": "cell-c8aefed6b2b8398e",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(R_P_System2), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "773a7d83f5998b44de6f0af2d35ed94f",
     "grade": false,
     "grade_id": "88v",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.8 extra\n",
    "\n",
    "1. On the same data is used in the previous exercise, what would the MAP be when there would be 10 relevant documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "75df7a1552351d14bc2a622f20081d00",
     "grade": false,
     "grade_id": "88a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "MAP_System1ex = 1/1 # replace with your answer\n",
    "MAP_System2ex = 1/1 # replace with your answer\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "125540b05112f0e8ecea9458fa616f70",
     "grade": true,
     "grade_id": "88t",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(MAP_System1ex), float)\n",
    "assert_equal(type(MAP_System2ex), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "145183e2b1ba270789d3a8f18cb14e85",
     "grade": false,
     "grade_id": "cell-1f877ea183d14013",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.9\n",
    "\n",
    "The following list of Rs and Ns represents relevant (R) and nonrelevant (N) returned documents in a ranked list of 20 documents retrieved in response to a query from a collection of 10,000 documents. The top of the ranked list (the document the system thinks is most likely to be relevant) is on the left of the list. This list shows 6 relevant documents. Assume that there are 8 relevant documents in total in the collection.\n",
    "\n",
    " > R R N N N $\\quad$ N N N R N $\\quad$ R N N N R $\\quad$ N N N N R\n",
    "\n",
    "1. What is the precision of the system on the top 20? (variable `precision`)\n",
    "2. What is the F1 on the top 20? (variable `F1`)\n",
    "3. What is the uninterpolated precision of the system at 25% recall? (variable `uninterpolated`)\n",
    "4. What is the interpolated precision at 33% recall? (variable `interpolated`)\n",
    "5. Assume that these 20 documents are the complete result set of the system. What is the AP for the query?<br/><br/>\n",
    "Assume, now, instead, that the system returned the entire 10,000 documents in a ranked list, and these are the first 20 results returned.<br/><br/>\n",
    "6. What is the largest possible AP that this system could have? (variable `largest_AP`)\n",
    "7. What is the smallest possible AP that this system could have? (variable `smallest_AP`)\n",
    "8. In a set of experiments, only the top 20 results are evaluated by hand. The result in (e) is used to approximate the range (f)–(g). For this example, how large (in absolute terms) can the error for the AP be by calculating (e) instead of (f) and (g) for this query? (variable `Error`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15b06a1b04586c07b10c9cda022f8c03",
     "grade": false,
     "grade_id": "cell-6ececd8d73bfc0ca",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3,\n",
       " 0.4285714285714285,\n",
       " 1,\n",
       " 0.36363636363636365,\n",
       " 0.5550505050505051,\n",
       " 0.5034090909090909,\n",
       " 0.4164753875387539,\n",
       " 0.13857511751175122)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 6/20\n",
    "F1 = ((2*(6/20)*(6/8))/((6/20)+(6/8)))\n",
    "uninterpolated = 1\n",
    "interpolated = 4/11\n",
    "AP_query = (1+1+3/9+4/11+5/15+6/20)/6\n",
    "largest_AP = (1+1+3/9+4/11+5/15+6/20+7/21+8/22)/8\n",
    "smallest_AP = (1+1+3/9+4/11+5/15+6/20+7/9999+8/10000)/8\n",
    "Error = max(abs((smallest_AP - AP_query)), abs(largest_AP - AP_query))\n",
    "\n",
    "precision, F1, uninterpolated, interpolated, AP_query, largest_AP, smallest_AP, Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "692448c0d136e60c5ced6e3abe8f4fd3",
     "grade": true,
     "grade_id": "cell-c2bb032e00c4dee1",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(precision) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d4b52d8e67f79a97cf5bf0a5f0b59ed",
     "grade": true,
     "grade_id": "cell-464b3522aa196af7",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(F1) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "217d3651897af1c4b8fbee04ce310b18",
     "grade": true,
     "grade_id": "cell-ee2af88f21b18a7d",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(uninterpolated) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daf0f299ac6ecc5f7545a662cbd9e16a",
     "grade": true,
     "grade_id": "cell-ee2af88f21b18a7dex",
     "locked": true,
     "points": 0.2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(interpolated) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5d6fe375a8f2dec0a947b37f066af0b",
     "grade": true,
     "grade_id": "cell-dd18f398ad9a11ea",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(AP_query) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d4a9d3e1f376f843680fb044f6f79b5",
     "grade": true,
     "grade_id": "cell-43dee696647831ac",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(largest_AP) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eeae02e405950f380a48bdecbdc7a06d",
     "grade": true,
     "grade_id": "cell-6efcd2c3d9ed173c",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(smallest_AP) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d437ef9bd15ea427fc681b643afb534",
     "grade": true,
     "grade_id": "cell-dcd93ad480d010ac",
     "locked": true,
     "points": 0.1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(Error) in [float,int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3aef48cb18e14805cdb8213df5707eee",
     "grade": false,
     "grade_id": "cell-653e5c66190845a3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 8.10\n",
    "Below is a table showing how two human judges rated the relevance of a set of 12 documents to a particular information need (0 = nonrelevant, 1 = relevant). Let us assume that you’ve written an IR system that for this query returns the set of documents {4, 5, 6, 7, 8}\n",
    "\n",
    "| docId | Judge 1 | Judge 2|\n",
    "|------:|:--------|:-------|\n",
    "| 1     | 0       | 0      |\n",
    "| 2     | 0       | 0      |\n",
    "| 3     | 1       | 1      |\n",
    "| 4     | 1       | 1      |\n",
    "| 5     | 1       | 0      |\n",
    "| 6     | 1       | 0      |\n",
    "| 7     | 1       | 0      |\n",
    "| 8     | 1       | 0      |\n",
    "| 9     | 0       | 1      |\n",
    "| 10    | 0       | 1      |\n",
    "| 11    | 0       | 1      |\n",
    "| 12    | 0       | 1      |\n",
    "\n",
    "1. Calculate the kappa measure between the two judges.\n",
    "2. Calculate precision, recall, and F1 of your system if a document is considered relevant only if the two judges agree.\n",
    "3. Calculate precision, recall, and F1 of your system if a document is considered relevant if either judge thinks it is relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb4c1b27e6776637331d142902b8ccac",
     "grade": false,
     "grade_id": "cell-72efecf88879db26",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.33333333333333337\n",
      "0.2 0.5 0.28571428571428575\n",
      "1 0.5 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "kappa = ((4/12) - (1/2)) / (1 - (1/2))\n",
    "\n",
    "# if the two judges agree.\n",
    "precision1 =  1/5\n",
    "recall1 =  1/2\n",
    "F1score1 = 2 * (precision1 * recall1) / (precision1 + recall1)\n",
    "\n",
    "# if either judge thinks it is relevant.\n",
    "precision2 = 1\n",
    "recall2 = 5/10\n",
    "F1score2 = 2 * (precision2 * recall2) / (precision2 + recall2)\n",
    "\n",
    "\n",
    "print(kappa)\n",
    "print(precision1, recall1, F1score1)\n",
    "print(precision2, recall2, F1score2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad86d4c9429ec0ee3fe6b13676b9c72c",
     "grade": true,
     "grade_id": "cell-d0b49ee6b738d816",
     "locked": true,
     "points": 0.33,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(kappa) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "627faf4e76f87e5cb92feb67972bb9fa",
     "grade": true,
     "grade_id": "cell-6c4430b58ad99642",
     "locked": true,
     "points": 0.33,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(precision1) in [float,int]\n",
    "assert type(recall1) in [float,int]\n",
    "assert type(F1score1) in [float,int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df6af0266e84e0a9a1d839637e6bba72",
     "grade": true,
     "grade_id": "cell-b4ddeb8ad1122e7e",
     "locked": true,
     "points": 0.34,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(precision2) in [float,int]\n",
    "assert type(recall2) in [float,int]\n",
    "assert type(F1score2) in [float,int]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "278dc547a0840b2625d16df9ef63fd62",
     "grade": false,
     "grade_id": "cell-db608e43be498940",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28898816090b94a56863e26251744777",
     "grade": false,
     "grade_id": "em-v",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Evaluation measures\n",
    "\n",
    "1. Define a function `Rprecision(ranked_list_of_results,list_of_relevant_objects)` which does what it says, it returns the R-precision given the input data.\n",
    "2. Define a function `AveragePrecision(ranked_list_of_results,list_of_relevant_objects)` which returns the average precision of this list of results given the list of relevant answers.\n",
    "\n",
    "Both functions of course come with one or two well chosen tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de18476927f4ff49054c47b24b947ed4",
     "grade": false,
     "grade_id": "em-a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25, 0.4]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here you can add helper functions if needed or handy\n",
    "def handyfunc():\n",
    "    print('wow very handy')\n",
    "    return\n",
    "\n",
    "def P_list(ranked_list_of_results, list_of_relevant_objects):\n",
    "    '''\n",
    "    This helper function stores all the precision values corresponding to whenever a relevant\n",
    "    document is retrieved in a list.\n",
    "    '''\n",
    "    p_list = []\n",
    "    tot_docs = 0\n",
    "    tot_rel_docs = 0\n",
    "    for doc in ranked_list_of_results:\n",
    "        tot_docs += 1\n",
    "        if doc in list_of_relevant_objects:\n",
    "            tot_rel_docs += 1\n",
    "            p_list.append(tot_rel_docs/tot_docs)\n",
    "\n",
    "    return p_list\n",
    "\n",
    "def Rprecision(ranked_list_of_results,list_of_relevant_objects):\n",
    "    answer = 0\n",
    "    for doc in ranked_list_of_results[:len(list_of_relevant_objects)]:\n",
    "        if doc in list_of_relevant_objects:\n",
    "            answer += 1\n",
    "    return answer / len(list_of_relevant_objects)\n",
    "    \n",
    "    \n",
    "def AveragePrecision(ranked_list_of_results, list_of_relevant_objects):\n",
    "    p_list = P_list(ranked_list_of_results, list_of_relevant_objects)\n",
    "    if p_list:\n",
    "        return sum(p_list) / len(p_list)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Hint Define a couple of good tests \n",
    "Rprecision([3,6,9,12,4], [1,3,6])\n",
    "Rprecision(['a', 'b','d','t'], ['q','r','s','t','u','v','w','x'])\n",
    "\n",
    "AveragePrecision(['a', 'b','d','t','u'], ['q','r','s','t','u','v','w','x'])\n",
    "P_list(['a', 'b','d','t','u'], ['q','r','s','t','u','v','w','x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9191f5774f4535d104d1fe42ae7b5db9",
     "grade": true,
     "grade_id": "em-t1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(Rprecision([1], [1]), float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d05f65deb46ae4ba034726c7805266c",
     "grade": true,
     "grade_id": "em-t2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(AveragePrecision([1], [1]), float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bcac3e11641ce8c14ae19db88da51fc4",
     "grade": false,
     "grade_id": "pr",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Precision recall curve\n",
    "\n",
    "We create the interpolated precision-recall curve as in Figure 8.2 in MRS for one topic. We use for this the file \n",
    "`qrels.robust2004.txt`.\n",
    "\n",
    "It is easy to read in your data using pandas. We give some code to get you started.\n",
    "\n",
    "Store your answer in the dict `PR` using the provided schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46211e4c53a958b9fba1b3e925b1e6a6",
     "grade": false,
     "grade_id": "prc",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP: topic 301 0.2999702080262656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOPIC</th>\n",
       "      <th>ITERATION</th>\n",
       "      <th>DOCUMENT_ID</th>\n",
       "      <th>RELEVANCY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>FBIS3-10397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TOPIC  ITERATION  DOCUMENT_ID  RELEVANCY\n",
       "0    301          0  FBIS3-10082          1\n",
       "1    301          0  FBIS3-10169          0\n",
       "2    301          0  FBIS3-10243          1\n",
       "3    301          0  FBIS3-10319          0\n",
       "4    301          0  FBIS3-10397          1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels= pd.read_csv('qrels.robust2004.txt', sep=' ', header=None, \n",
    "                   names=['TOPIC',      'ITERATION',      'DOCUMENT_ID',     'RELEVANCY'])# https://trec.nist.gov/data/robust/qrels.robust2004.txt\n",
    "\n",
    "\n",
    "# Create Figure8\n",
    "\n",
    "rankedlist= qrels[(qrels.TOPIC==301)].DOCUMENT_ID.unique()\n",
    "np.random.shuffle(rankedlist) # This causes that the PR curve is different all the time (and often quite weird)\n",
    "relevantdocs=set(qrels[(qrels.TOPIC==301)&(qrels.RELEVANCY==1)].DOCUMENT_ID.unique() )\n",
    "\n",
    "N= len(relevantdocs)\n",
    "Rlevels=[(r+1) /N for r in range(len(relevantdocs))] \n",
    "\n",
    "print('AP: topic 301', AveragePrecision(rankedlist,relevantdocs  ))\n",
    "\n",
    "qrels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01027c61279685324d810cc33e4b7e55",
     "grade": false,
     "grade_id": "pra",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Figure8.2 for topic 301\n",
    "\n",
    "# Use previously declared helper function to obtain precision values\n",
    "uninterp_list = P_list(rankedlist, relevantdocs)\n",
    "\n",
    "# Interpolate precision value list\n",
    "interp_list = []\n",
    "for i in range(len(uninterp_list)):\n",
    "    uninterpolated_val = uninterp_list[i] \n",
    "    interpolated_val = max(uninterp_list[i:])\n",
    "    if interpolated_val > uninterpolated_val:\n",
    "        interp_list.append(interpolated_val)\n",
    "    else:\n",
    "        interp_list.append(uninterpolated_val)\n",
    "        \n",
    "        \n",
    "\n",
    "# You must calculate the correct precison values for every given recall value here\n",
    "PR={'UninterpolatedP':dict(zip(Rlevels, uninterp_list)), 'InterpolatedP':dict(zip(Rlevels, interp_list))}\n",
    "\n",
    "\n",
    "pd.DataFrame(PR).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "326d67024d102de958f6dab1f96d765f",
     "grade": true,
     "grade_id": "prt",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert set(PR.keys())=={'UninterpolatedP', 'InterpolatedP'}\n",
    "for K in PR:\n",
    "     assert isinstance(PR[K],dict)\n",
    "assert_equal(set(PR['UninterpolatedP'].keys()),set(Rlevels))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d409e7643408910bcf2f768c2df01899",
     "grade": false,
     "grade_id": "ck-v",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Cohen's Kappa\n",
    "\n",
    "Compute the chance $P(E)$ used in the calculation of Cohen's Kappa, using the pooled marginals method.\n",
    "\n",
    "Your data looks like that given in Exercise 8.10: An array of pairs with binary relevance judgements in which the first column contains the scores of the first judge, etc.\n",
    "\n",
    "Hint: `numpy` arrays have all kind of handy methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4416d9b5b37301b3a183748753f90b7",
     "grade": false,
     "grade_id": "ck-a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input data size of kappa must be like this\n",
    "data= np.array([[1,1],[1,0],[0,1],[1,1],[0,0]])\n",
    "def PE(data):\n",
    "    '''On input `data`, return the   P(E) (expected agreement).'''\n",
    "     \n",
    "    data = np.array(data)\n",
    "    \n",
    "    # Count 0's and 1's in data and store count\n",
    "    tot_0 = 0\n",
    "    tot_1 = 0\n",
    "    tot_rows = 0\n",
    "    for row in data:\n",
    "        tot_rows += 1\n",
    "        for judge in row:\n",
    "            if judge:\n",
    "                tot_1 += 1\n",
    "            else:\n",
    "                tot_0 += 1\n",
    "                \n",
    "    # Here I assume that the data contains only lists of the same length                   \n",
    "    nonrelevant_p = (tot_0 / (tot_rows * len(data[0])))\n",
    "    relevant_p = (tot_1 / (tot_rows * len(data[0])))\n",
    "        \n",
    "    return nonrelevant_p**2 + relevant_p**2\n",
    "                  \n",
    "\n",
    "PE(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cf21d47e9b7070cf58716b8627b85aa",
     "grade": true,
     "grade_id": "ck-t",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(PE(data), float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "627ad98ff8f230481ad539fd36a2df43",
     "grade": false,
     "grade_id": "cell-891a3bbce2d771fa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 10.1 Creating a test set\n",
    "\n",
    "Create a test collection in order to evaluate your two search engines (cosine similarity and BM25) on the set of Shakespeare. Create five information needs, which you express as queries. Use multi term queries only. For each information need you specify\n",
    "\n",
    " * The information need in natural language\n",
    " * The search query\n",
    " * A description when a document is considered relevant and when it is not. This should be a very clear description. A person assessing relevance may only use this together with the information need to determine relevance of a document. In particular the judge should not see the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "52040542d5f6c5c6fea8d35ad4a1ffb5",
     "grade": true,
     "grade_id": "cell-3fd2c07428004c67",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Information needs: <br />\n",
    "1 The documents that contain the most instances of the sentence: Mine honest neighbour. <br />\n",
    "2 The documents that contain the most instances of the sentence: I tell you. <br />\n",
    "3 The documents that contain the most instances of the sentence: This is strange. <br />\n",
    "4 The documents that contain the most instances of the sentence: They have a leader! <br />\n",
    "5 The documents that contain the most instances of the sentence: The gods assist you! <br />\n",
    "\n",
    "\n",
    "\n",
    "Queries: <br />\n",
    "1 [mine & honest & neighbour] <br />\n",
    "2 [i & tell & you] <br />\n",
    "3 [this & is & strange] <br />\n",
    "4 [they & have & a & leader] <br />\n",
    "5 [the & gods & assist & you] <br />\n",
    "\n",
    "Description:\n",
    "1 A doc is relevant when it contains at least 1 utterance of the sentence: 'Mine honest neighbour'. The more utterances, the more relevant it is.  <br />\n",
    "2 A doc is relevant when it contains at least 1 utterance of the sentence: 'I tell you'. The more utterances, the more relevant it is.  <br />\n",
    "3 A doc is relevant when it contains at least 1 utterance of the sentence: 'This is strange'. The more utterances, the more relevant it is.  <br />\n",
    "4 A doc is relevant when it contains at least 1 utterance of the sentence: 'They have a leader'. The more utterances, the more relevant it is.  <br />\n",
    "5 A doc is relevant when it contains at least 1 utterance of the sentence: 'The gods assist you'. The more utterances, the more relevant it is.  <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16f16b8c95fcffd6029b5cfde151fa75",
     "grade": false,
     "grade_id": "cell-1af8400eea1e3e8e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 10.2 Assess search engine results\n",
    "\n",
    "Assess for your two search engines, for all five information needs the first 10 results given back by the systems. Let another student do the same task as well.\n",
    "1. Using your own relevance judgments, compute for each system, the precision at 10 for each query, and the average P@10. Discuss the results.\n",
    "2. You have now two times at least 50 relevance judgements, and probably more. Compute the kappa measure between the two judges as in exercise 8.10, using pooled marginals as in Table 8.2. Discuss your results and try to explain them.\n",
    "3. Now compute P@10 for both systems again, once using the relevance judgments of the other assessor, once in which you say that a document is relevant if BOTH judges said it was relevant, and once in which you say that a document is relevant if AT LEAST ONE of the judges said it was relevant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "668cb299c87264fda9c0bb50078702d1",
     "grade": true,
     "grade_id": "cell-1f5104381710e6d4",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Results given back by cosine similarity: <br />\n",
    "Results given back by BM25: <br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "64b042a414ab4186ff36da8de10fc0ca",
     "grade": false,
     "grade_id": "cell-0828c47c6c841ab2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Programming (Inverted Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45265903cced267bded49289c1a33748",
     "grade": false,
     "grade_id": "cell-ee70e59824b4530f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def loadShakespeare():\n",
    "    if 'shaks200.zip' in os.listdir():\n",
    "        return 'shaks200.zip'\n",
    "    elif os.path.exists('../../data/Week3/'):\n",
    "        return '../../data/Week3/shaks200.zip'\n",
    "    elif os.path.exists('../../../data/Week3/'):\n",
    "        return '../../../data/Week3/shaks200.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a291330f776161fa4f004ba6e02d511",
     "grade": false,
     "grade_id": "cell-2cd22bbe0ed6e5b5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 12 Positional inverted index\n",
    "Adjust your software making an inverted index for the Shakespeare collection: the output should be a positional index. A positional index is an index that also stores the position of the occurrences of a word in a document. The following figure shows an example of a positional index.\n",
    "\n",
    "<img src=\"http://nlp.stanford.edu/IR-book/html/htmledition/img121.png\" />\n",
    "\n",
    "Make the index of the form (defaultdicts are also allowed!):\n",
    "```\n",
    "{'caesar':   {'files': \n",
    "                 {'lll': {'list': [25350], 'total': 1},\n",
    "                  'm_for_m': {'list': [6773, 14734], 'total': 2},\n",
    "                  'm_wives': {'list': [3459], 'total': 1},\n",
    "                  'macbeth': {'list': [9256], 'total': 1},\n",
    "                  'othello': {'list': [11728], 'total': 1},\n",
    "                  'rich_ii': {'list': [22695], 'total': 1},\n",
    "                  'rich_iii': {'list': [16418, 16570, 30799, 30801], 'total': 4},\n",
    "                  'titus': {'list': [368], 'total': 1},\n",
    "                  ....\n",
    "                  },\n",
    "               'total': 604}....\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5d6c8aae378a5c4105975e2845550b86",
     "grade": true,
     "grade_id": "cell-498f786fcde3299d",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-43e88d85f96a>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for infile in tqdm_notebook(namelist): # loop over each file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b65515970846bf9351de7ae5e9bfb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'files': {'a_and_c': {'list': [18252, 26437], 'total': 2},\n",
       "  'all_well': {'list': [7951, 19330], 'total': 2},\n",
       "  'as_you': {'list': [7728], 'total': 1},\n",
       "  'com_err': {'list': [5067, 5086, 5417, 5456, 5803, 7298, 11139], 'total': 7},\n",
       "  'coriolan': {'list': [7379, 7658, 20273], 'total': 3},\n",
       "  'cymbelin': {'list': [2086, 6901], 'total': 2},\n",
       "  'dream': {'list': [7211, 7365, 8103, 8243, 11974, 12404, 13449, 16411],\n",
       "   'total': 8},\n",
       "  'hamlet': {'list': [11465, 12935, 26725, 26910], 'total': 4},\n",
       "  'hen_iv_2': {'list': [5833, 7814], 'total': 2},\n",
       "  'hen_v': {'list': [9577, 15481, 15502], 'total': 3},\n",
       "  'j_caesar': {'list': [14575, 14616], 'total': 2},\n",
       "  'john': {'list': [3713, 3715], 'total': 2},\n",
       "  'lear': {'list': [5764, 6281], 'total': 2},\n",
       "  'lll': {'list': [6597, 6614, 20594, 20619], 'total': 4},\n",
       "  'm_for_m': {'list': [9649, 22842], 'total': 2},\n",
       "  'm_wives': {'list': [1453, 9332, 9335, 22610], 'total': 4},\n",
       "  'much_ado': {'list': [17403,\n",
       "    17407,\n",
       "    17431,\n",
       "    17439,\n",
       "    17453,\n",
       "    17548,\n",
       "    19701,\n",
       "    20114],\n",
       "   'total': 8},\n",
       "  'othello': {'list': [514, 8615], 'total': 2},\n",
       "  'rich_ii': {'list': [23231], 'total': 1},\n",
       "  't_night': {'list': [1582, 6058, 7128, 7315, 7317, 11708, 18192, 18204],\n",
       "   'total': 8},\n",
       "  'taming': {'list': [5989, 10622, 13204, 19936], 'total': 4},\n",
       "  'tempest': {'list': [17108], 'total': 1},\n",
       "  'timon': {'list': [2364, 9924, 14990, 14995, 15161], 'total': 5},\n",
       "  'titus': {'list': [13554], 'total': 1},\n",
       "  'troilus': {'list': [6994, 16698, 22593, 22599, 22612, 25598], 'total': 6},\n",
       "  'two_gent': {'list': [5170, 7202, 7359, 16489], 'total': 4}},\n",
       " 'total': 90}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def positional_inverted_index(zipfolder):\n",
    "    # With zipfile we can read the file without opening the zip file\n",
    "    archive = zipfile.ZipFile(zipfolder, 'r')\n",
    "    namelist = [x for x in archive.namelist() if '.xml' in x]\n",
    "    \n",
    "    \n",
    "    positional_index = defaultdict(lambda: defaultdict(int)) # Init positional index\n",
    "    \n",
    "    for infile in tqdm_notebook(namelist): # loop over each file\n",
    "        f = archive.open(infile)\n",
    "        filename = str(infile).replace('.xml','' ) # name of current file\n",
    "        \n",
    "        # use Beautifulsoup to extract text from xml files\n",
    "        # remove non alphabetical characters in file and tokenize\n",
    "        soup = BeautifulSoup(f, 'xml')\n",
    "        # remove 's to pass test\n",
    "        regex = re.compile(\"'s\")\n",
    "        regex2 = re.compile('[^a-zA-Z\\s]')\n",
    "        del_apo = regex.sub('', soup.get_text())\n",
    "        onlyalph = regex2.sub('', del_apo)\n",
    "        tokenized_f = onlyalph.lower().split() # Add all tokens to list\n",
    "        \n",
    "        counter = 0\n",
    "        for token in tokenized_f:\n",
    "            if token in positional_index:\n",
    "                if filename in positional_index[token]['files']:\n",
    "                    positional_index[token]['files'][filename]['list'].append(counter)\n",
    "                    positional_index[token]['files'][filename]['total'] += 1\n",
    "                    positional_index[token]['total'] += 1\n",
    "                else:\n",
    "                    positional_index[token]['files'][filename] = {'list':[counter], 'total':1}\n",
    "                    positional_index[token]['total'] += 1\n",
    "                    \n",
    "            else:\n",
    "                positional_index[token] = {'files': {filename:{'list':[counter], 'total':1}}, 'total':1}\n",
    "           \n",
    "            counter+=1\n",
    "                \n",
    "    return positional_index\n",
    "\n",
    "positional_index = positional_inverted_index(loadShakespeare())\n",
    "positional_index['ass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b6e21d8ffeb36779f0b33421a0797a57",
     "grade": true,
     "grade_id": "cell-29881806b7e5b184",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-43e88d85f96a>:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for infile in tqdm_notebook(namelist): # loop over each file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eefb13d69d84f6daa9201ab7420c745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positional_index = positional_inverted_index(loadShakespeare())\n",
    "assert type(positional_index) in [dict, defaultdict]\n",
    "assert_equal(set(positional_index['the'].keys()), {'total','files'})\n",
    "assert_equal(type(positional_index['the']['total']), int)\n",
    "assert_equal(set(positional_index['the']['files']['lll'].keys()), {'total','list'})\n",
    "assert_equal(type(positional_index['the']['files']['lll']['list']), list)\n",
    "assert_equal(type(positional_index['the']['files']['lll']['total']), int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
