{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csovgowtSchs"
   },
   "source": [
    "# Zoekmachines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipBlgebESchw"
   },
   "source": [
    "## Notebook made by\n",
    "\n",
    "__Name__|Levi| en vrienden\n",
    "\n",
    "__Student id__ : secret\n",
    "\n",
    "__Name__|Raoul| en vrienden\n",
    "\n",
    "__Student id__ : secret\n",
    "\n",
    "__Name__|Daniël| en vrienden\n",
    "\n",
    "__Student id__ : secret\n",
    "\n",
    "__Name__|Philip| en vrienden\n",
    "\n",
    "__Student id__ : secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEyqPU5ySchw"
   },
   "source": [
    "## Toelichting\n",
    "\n",
    "* De meeste opgaven worden automatisch nagekeken. Bij vrijwel alle opdrachten staan er een paar zichtbare tests onder de opdracht, dit is voornamelijk om te zorgen dat je de juiste type output geeft. De andere tests worden na inleveren toegevoegd aan die cell.\n",
    "\n",
    "## Voor het inleveren!\n",
    "\n",
    "* Pas niet de cellen aan, vooral niet die je niet kunt editen. Dit levert problemen op bij nakijken. Twijfel je of je per ongeluk iets hebt gewijzigd, kopieer dan bij inleveren je antwoorden naar een nieuw bestand, zodat het niet fout kan gaan.\n",
    "\n",
    "* Zorg dat de code goed runt van boven naar beneden, verifieer dat door boven in Kernel -> Restart & Run All uit te voeren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRc-371xSchx",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Week-2\" data-toc-modified-id=\"Week-2-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Week 2</a></span></li><li><span><a href=\"#Book-exercises\" data-toc-modified-id=\"Book-exercises-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Book exercises</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#2.1\" data-toc-modified-id=\"2.1-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>2.1</a></span></li><li><span><a href=\"#2.2-(not-graded)\" data-toc-modified-id=\"2.2-(not-graded)-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>2.2 (not graded)</a></span></li><li><span><a href=\"#2.3\" data-toc-modified-id=\"2.3-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>2.3</a></span></li><li><span><a href=\"#2.4-(not-graded)\" data-toc-modified-id=\"2.4-(not-graded)-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>2.4 (not graded)</a></span></li><li><span><a href=\"#2.8-(not-graded)\" data-toc-modified-id=\"2.8-(not-graded)-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>2.8 (not graded)</a></span></li><li><span><a href=\"#2.9\" data-toc-modified-id=\"2.9-2.0.6\"><span class=\"toc-item-num\">2.0.6&nbsp;&nbsp;</span>2.9</a></span></li><li><span><a href=\"#2.10\" data-toc-modified-id=\"2.10-2.0.7\"><span class=\"toc-item-num\">2.0.7&nbsp;&nbsp;</span>2.10</a></span></li><li><span><a href=\"#6.9\" data-toc-modified-id=\"6.9-2.0.8\"><span class=\"toc-item-num\">2.0.8&nbsp;&nbsp;</span>6.9</a></span></li><li><span><a href=\"#6.10\" data-toc-modified-id=\"6.10-2.0.9\"><span class=\"toc-item-num\">2.0.9&nbsp;&nbsp;</span>6.10</a></span></li><li><span><a href=\"#6.11-(not-graded)\" data-toc-modified-id=\"6.11-(not-graded)-2.0.10\"><span class=\"toc-item-num\">2.0.10&nbsp;&nbsp;</span>6.11 (not graded)</a></span></li><li><span><a href=\"#6.12-(not-graded)\" data-toc-modified-id=\"6.12-(not-graded)-2.0.11\"><span class=\"toc-item-num\">2.0.11&nbsp;&nbsp;</span>6.12 (not graded)</a></span></li><li><span><a href=\"#6.13-(not-graded)\" data-toc-modified-id=\"6.13-(not-graded)-2.0.12\"><span class=\"toc-item-num\">2.0.12&nbsp;&nbsp;</span>6.13 (not graded)</a></span></li><li><span><a href=\"#6.14-(not-graded)\" data-toc-modified-id=\"6.14-(not-graded)-2.0.13\"><span class=\"toc-item-num\">2.0.13&nbsp;&nbsp;</span>6.14 (not graded)</a></span></li><li><span><a href=\"#6.15\" data-toc-modified-id=\"6.15-2.0.14\"><span class=\"toc-item-num\">2.0.14&nbsp;&nbsp;</span>6.15</a></span></li><li><span><a href=\"#6.16-(not-graded)\" data-toc-modified-id=\"6.16-(not-graded)-2.0.15\"><span class=\"toc-item-num\">2.0.15&nbsp;&nbsp;</span>6.16 (not graded)</a></span></li><li><span><a href=\"#6.17\" data-toc-modified-id=\"6.17-2.0.16\"><span class=\"toc-item-num\">2.0.16&nbsp;&nbsp;</span>6.17</a></span></li></ul></li></ul></li><li><span><a href=\"#Extra-theory-exercises\" data-toc-modified-id=\"Extra-theory-exercises-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Extra theory exercises</a></span><ul class=\"toc-item\"><li><span><a href=\"#Index-size\" data-toc-modified-id=\"Index-size-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Index size</a></span></li><li><span><a href=\"#Index-size-2\" data-toc-modified-id=\"Index-size-2-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Index size 2</a></span></li></ul></li><li><span><a href=\"#Programming-(Inverted-Index)\" data-toc-modified-id=\"Programming-(Inverted-Index)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Programming (Inverted Index)</a></span><ul class=\"toc-item\"><li><span><a href=\"#9-Ranked-Retrieval\" data-toc-modified-id=\"9-Ranked-Retrieval-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>9 Ranked Retrieval</a></span></li><li><span><a href=\"#9.1-TF-IDF\" data-toc-modified-id=\"9.1-TF-IDF-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>9.1 TF-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#9.2-TF-IDF-Ranked-Search\" data-toc-modified-id=\"9.2-TF-IDF-Ranked-Search-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>9.2 TF-IDF Ranked Search</a></span></li><li><span><a href=\"#9.3-Vector-Space-Model\" data-toc-modified-id=\"9.3-Vector-Space-Model-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>9.3 Vector Space Model</a></span></li><li><span><a href=\"#9.4-Cosine-Similarity\" data-toc-modified-id=\"9.4-Cosine-Similarity-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>9.4 Cosine Similarity</a></span></li><li><span><a href=\"#9.5-Okapi-BM25\" data-toc-modified-id=\"9.5-Okapi-BM25-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>9.5 Okapi BM25</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5dShsXXTSch0",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9fbfec4f0391fb1311b40615454a2b4",
     "grade": false,
     "grade_id": "cell-d32efc5c56bf7199",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "T7dy6KKcSch1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "630bc803cc5920da4bbaf276dc195f58",
     "grade": false,
     "grade_id": "cell-e86d56c9ad0aa4e5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "e0b348c2-ed9c-4303-9d58-721e9c908590"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nose\n",
      "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
      "\u001b[?25l\r",
      "\u001b[K     |██▏                             | 10 kB 24.0 MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 20 kB 27.1 MB/s eta 0:00:01\r",
      "\u001b[K     |██████▍                         | 30 kB 12.5 MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 40 kB 9.8 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 51 kB 5.1 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 61 kB 5.5 MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 71 kB 5.9 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 81 kB 6.6 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 92 kB 6.7 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 102 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 112 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 122 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 133 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 143 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 153 kB 5.2 MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 154 kB 5.2 MB/s \n",
      "\u001b[?25hInstalling collected packages: nose\n",
      "Successfully installed nose-1.3.7\n"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_equal, assert_almost_equal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KuP_97soSch2",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96b23d353367523fb2e238baade2a528",
     "grade": false,
     "grade_id": "cell-2ea109d597cac3d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Book exercises\n",
    "In this section you will make the exercises from the book, which is freely available online as a PDF at [nlp.stanford.edu/IR-book/](http://nlp.stanford.edu/IR-book/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "id": "fgY84k7ySch3",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ec04407cf35c76af81cd3c58077931e",
     "grade": false,
     "grade_id": "cell-675cbcb22f189c5c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1\n",
    "\n",
    "Are the following statements true or false?\n",
    "\n",
    "a. In a Boolean retrieval system, stemming never lowers precision.\n",
    "\n",
    "b. In a Boolean retrieval system, stemming never lowers recall.\n",
    "\n",
    "c. Stemming increases the size of the vocabulary.\n",
    "\n",
    "d. Stemming should be invoked at indexing time but not while processing a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "OT4LqVheSch3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae72a753a09a3a013f5996e05006eb61",
     "grade": false,
     "grade_id": "cell-9fba209db4797a78",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "14af4945-b779-44fd-a8b7-40c62fead541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False, False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = False # Replace with your answer\n",
    "b =  True # Replace with your answer\n",
    "c = False # Replace with your answer\n",
    "d = False # Replace with your answer\n",
    "\n",
    "#Ik dacht dus het volgende maar hebben we het tijdens wg wel over - Raoul\n",
    "\n",
    "# a = False # Replace with your answer\n",
    "# b = True # Replace with your answer\n",
    "# c = False # Replace with your answer\n",
    "# d = True # Replace with your answer\n",
    "\n",
    "\n",
    "a, b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "essQRTLBSch4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cb829764eefb004110c89bab32200fc",
     "grade": true,
     "grade_id": "cell-fc1c070acbfa02f6",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(a), bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OHklssw-Sch4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "327b6613bdaacdfccd7bd248a97c9a0c",
     "grade": true,
     "grade_id": "cell-323357d08fec7701",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(b), bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KO97Xt6hSch4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a287baf29f0d2f5fe3b29633eba3ce57",
     "grade": true,
     "grade_id": "cell-8d2d64004b40ab52",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(c), bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0OyfxFpjSch5",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63a327b74f2cf3d55a4e51bac0649b73",
     "grade": true,
     "grade_id": "cell-e3f19c4c556a014a",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(d), bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TAGoKJ_kSch5",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f064953d97ee1b4f32ee659132409aea",
     "grade": false,
     "grade_id": "cell-e823f1efc7adcaba",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.2 (not graded)\n",
    "\n",
    "Suggest what normalized form should be used for these words (including the word\n",
    "itself as a possibility):\n",
    "1. ’Cos\n",
    "2. Shi’ite\n",
    "3. cont’d\n",
    "4. Hawai’i\n",
    "5. O’Rourke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BFTFDFv1Sch5",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82b6952dc64bcf927f866b4df73312fa",
     "grade": false,
     "grade_id": "cell-3eb40501c393b362",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "a) 'Cos: cos ( The ' is not a information in text it more a conection between words.)<br/>\n",
    "b) Shi'ite: shiite (this the same as next)<br/>\n",
    "c) cont'd: contd<br/>\n",
    "d) Hawai'i: hawaii (Hawai'i, hawai'i, Hawaii)<br/>\n",
    "e) O'Rourke: orourke (O'Rourke, o'rourke, ORourke)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "586KabU6Sch6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9cc4f86fae84ee0f7e3aad6ad19051e2",
     "grade": false,
     "grade_id": "cell-3d752b81075d9d59",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.3\n",
    "\n",
    "The following pairs of words are stemmed to the same form by the Porter stemmer.\n",
    "Which pairs would you argue shouldn’t be conflated. Give your reasoning.\n",
    "1. abandon/abandonment\n",
    "2. absorbency/absorbent\n",
    "3. marketing/markets\n",
    "4. university/universe\n",
    "5. volume/volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "UGRckKfgSch6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "981ce4c849ceb781660368b32e8a0bd1",
     "grade": false,
     "grade_id": "203",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "should=set({1,2,5}) # answer as a set of numbers between 1 and 5\n",
    "shouldnot=set({3,4})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Pj9EZ3UASch6",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc83af6df0a6e08d08edea1405387b17",
     "grade": true,
     "grade_id": "203-t",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(should), set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rzdEmXbpSch7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f68eae612fde17e8990a052accdf0ca",
     "grade": false,
     "grade_id": "cell-bed75dda3272a6ec",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.4 (not graded)\n",
    "\n",
    "For the Porter stemmer rule group shown in (2.1):\n",
    "1. What is the purpose of including an identity rule such as SS → SS?\n",
    "2. Applying just this rule group, what will the following words be stemmed to?\n",
    "   > _circus_ _canaries_ _boss_\n",
    "3. What rule should be added to correctly stem pony?\n",
    "4. The stemming for ponies and pony might seem strange. Does it have a deleterious effect on retrieval? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jI-wFndvSch7",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fffd9e79acf9c04c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "1. The purpose of including an identity such as SS->SS is to prevent the wrong stemming of words like caress using the rule s->nothing.\n",
    "* circus->circu, canaries->canari, boss->boss\n",
    "* y->i\n",
    "*  so ponies -> poni and pony -> poni we can see  that poni might get more forms will be stemed to this from. like if ponzi scheme was spelld incorrectly in one of your documents you can get the same word. and this makes it less usefull.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hMX8U7OWSch7",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06c9a4bf72abdd34619bd5aabb16ac7f",
     "grade": false,
     "grade_id": "cell-e69cd0806b78c2e5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.8 (not graded)\n",
    "\n",
    "Assume a biword index. Give an example of a document which will be returned\n",
    "for a query of New York University but is actually a false positive which should not be\n",
    "returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBIUZ2BPSch8",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48f9c4a70c356cb9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Research on New York, done at York University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "CODOVIyoSch8",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7552f71351167a476319e9900fb1796",
     "grade": false,
     "grade_id": "cell-63f4fe400c5affd4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.9\n",
    "\n",
    "Shown below is a portion of a positional index in the format:\n",
    "> term: doc1: $\\langle$ position1, position2, . . . $\\rangle$; doc2: $\\langle$ position1, position2, . . .$\\rangle$; etc.\n",
    "\n",
    "angels: 2: $\\langle$36,174,252,651$\\rangle$; 4: $\\langle$12,22,102,432$\\rangle$; 7: $\\langle$17$\\rangle$;<br/>\n",
    "fools: 2: $\\langle$1,17,74,222$\\rangle$; 4: $\\langle$8,78,108,458$\\rangle$; 7: $\\langle$3,13,23,193$\\rangle$;<br/>\n",
    "fear: 2: $\\langle$87,704,722,901$\\rangle$; 4: $\\langle$13,43,113,433$\\rangle$; 7: $\\langle$18,328,528$\\rangle$;<br/>\n",
    "in: 2: $\\langle$3,37,76,444,851$\\rangle$; 4: $\\langle$10,20,110,470,500$\\rangle$; 7: $\\langle$5,15,25,195$\\rangle$;<br/>\n",
    "rush: 2: $\\langle$2,66,194,321,702$\\rangle$; 4: $\\langle$9,69,149,429,569$\\rangle$; 7: $\\langle$4,14,404$\\rangle$;<br/>\n",
    "to: 2: $\\langle$47,86,234,999$\\rangle$; 4: $\\langle$14,24,774,944$\\rangle$; 7: $\\langle$199,319,599,709$\\rangle$;<br/>\n",
    "tread: 2: $\\langle$57,94,333$\\rangle$; 4: $\\langle$15,35,155$\\rangle$; 7: $\\langle$20,320$\\rangle$;<br/>\n",
    "where: 2: $\\langle$67,124,393,1001$\\rangle$; 4: $\\langle$11,41,101,421,431$\\rangle$; 7: $\\langle$16,36,736$\\rangle$;\n",
    "\n",
    "Which document(s) if any match each of the following queries, where each expression\n",
    "within quotes is a phrase query?\n",
    "1. “fools rush in”\n",
    "2. “fools rush in” AND “angels fear to tread”\n",
    "\n",
    "Give your answer as sets, respectively `firstphrase` and `secondphrase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "FeIud3YqSch9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5638f028b98c5844bbe4becee9425436",
     "grade": false,
     "grade_id": "cell-04b90595b2cf07b8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "firstphrase = set([2,4,7])\n",
    "secondphrase = set([4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "pt3CvImWSch9",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bdc3f6d488713b88e2bf9b42027bdfe",
     "grade": true,
     "grade_id": "cell-32f1ec171801d213",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(firstphrase),set)\n",
    "assert_equal(type(secondphrase),set)\n",
    "for x in firstphrase:\n",
    "    assert x in [2,4,7]\n",
    "for x in secondphrase:\n",
    "    assert x in [2,4,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "id": "DP4ykcopSch-",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c48da0d0d660996de269fe685bd474a9",
     "grade": false,
     "grade_id": "cell-fc519c5fe85e638a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.10\n",
    "\n",
    "Consider the following fragment of a positional index with the format:\n",
    "\n",
    "> word: document: $\\langle$position, position, . . .$\\rangle$; document: $\\langle$position, . . .$\\rangle$<br />\n",
    ". . .\n",
    "\n",
    ">Gates: 1: $\\langle$3$\\rangle$; 2: $\\langle$6$\\rangle$; 3: $\\langle$2,17$\\rangle$; 4: $\\langle$1$\\rangle$;<br />\n",
    "IBM: 4: $\\langle$3$\\rangle$; 7: $\\langle$14$\\rangle$;<br />\n",
    "Microsoft: 1: $\\langle$1$\\rangle$; 2: $\\langle$1,21$\\rangle$; 3: $\\langle$3$\\rangle$; 5: $\\langle$16,22,51$\\rangle$;\n",
    "\n",
    "The $/k$ operator, word1 $/k$ word2 finds occurrences of word1 within $k$ words of word2 (on either side), where $k$ is a positive integer argument. Thus $k = 1$ demands that word1 be adjacent to word2.\n",
    "1. Describe the set of documents that satisfy the query Gates $/2$ Microsoft.\n",
    "2. Describe for each value  $k$ between 1 and 7 the set of documents returned after the   query Gates $/k$ Microsoft.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "7f05ZnY0Sch_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3e1268104f09f866b5290e9886c935e",
     "grade": false,
     "grade_id": "cell-31e611774e33399f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "k1 = set([3])\n",
    "k2 = set([1,3])\n",
    "k3 = set([1,3])\n",
    "k4 = set([1,3])\n",
    "k5 = set([1,2,3])\n",
    "k6 = set([1,2,3])\n",
    "k7 = set([1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "PIHWzSoJSch_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d58a744476a8966380e5a06b66215d23",
     "grade": true,
     "grade_id": "cell-b933f7947f3f78db",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for k in [k1,k2,k3,k4,k5,k6,k7]:\n",
    "    assert_equal(type(k),set)\n",
    "    assert k.issubset({1,2,3,4,5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "TUys8GHWSciA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa8ce28acd7139228b14cc498761066c",
     "grade": false,
     "grade_id": "cell-28339956b6d5bd88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.9\n",
    "\n",
    "What is the idf of a term that occurs in every document (variable `idf_every_doc`)? Compare this with the use of stop word lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "kr1SX2k4SciA",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d81786146a40dce3fa159fe47f00d450",
     "grade": false,
     "grade_id": "cell-84323557f1b57844",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "idf_every_doc = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XcnMA_wASciA",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ff52eb8374fc8ae787529b4d72debc1",
     "grade": true,
     "grade_id": "cell-3cbf108756459c24",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(idf_every_doc) in [int, float]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "W4HnC_ojSciB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0800b3534752364a4c5ab17e61e9220",
     "grade": false,
     "grade_id": "cell-614376aa2b170562",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.10\n",
    "\n",
    "Consider the table of term frequencies for 3 documents denoted Doc1, Doc2, Doc3 in Figure 6.9. Compute the tf-idf weights for the terms car, auto, insurance, best, for each document, using the idf values from Figure 6.8.\n",
    "\n",
    "Note that we use tf-idf weighting **with the raw tf values** in this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "qaEgclx1SciB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98647192fe173f6c177c5a75e2e8077e",
     "grade": false,
     "grade_id": "cell-3753d6674d83ae0e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "358234b8-8724-4c2d-a558-580f02b598ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc1: [44.55, 6.24, 0.0, 21.0]\n",
      "Doc2: [6.6, 68.64, 53.46, 0.0]\n",
      "Doc3: [39.599999999999994, 0.0, 46.980000000000004, 25.5]\n"
     ]
    }
   ],
   "source": [
    "# for Doc1\n",
    "tfidf_car1 = 1.65 * 27\n",
    "tfidf_auto1 = 2.08 * 3\n",
    "tfidf_insurance1 = 1.62 * 0\n",
    "tfidf_best1 =  1.5 * 14\n",
    "# for Doc2\n",
    "tfidf_car2 = 1.65 * 4\n",
    "tfidf_auto2 = 2.08 * 33\n",
    "tfidf_insurance2 = 1.62 * 33\n",
    "tfidf_best2 =  1.5 * 0\n",
    "# for Doc3\n",
    "tfidf_car3 = 1.65 * 24\n",
    "tfidf_auto3 = 2.08 * 0\n",
    "tfidf_insurance3 = 1.62 * 29\n",
    "tfidf_best3 =  1.5 * 17\n",
    "\n",
    "\n",
    "print(\"Doc1: [%s, %s, %s, %s]\" %(tfidf_car1, tfidf_auto1, tfidf_insurance1, tfidf_best1))\n",
    "print(\"Doc2: [%s, %s, %s, %s]\" %(tfidf_car2, tfidf_auto2, tfidf_insurance2, tfidf_best2))\n",
    "print(\"Doc3: [%s, %s, %s, %s]\" %(tfidf_car3, tfidf_auto3, tfidf_insurance3, tfidf_best3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hrQ4uWwiSciB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a86bb42f5fc40279545c5c5000b8e847",
     "grade": true,
     "grade_id": "cell-d465a3ce0a126ca9",
     "locked": true,
     "points": 0.34,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(tfidf_car1), float)\n",
    "assert_equal(type(tfidf_auto1), float)\n",
    "assert_equal(type(tfidf_insurance1), float)\n",
    "assert_equal(type(tfidf_best1), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7rls1eBESciC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6df9c1f94026f853ad109c41c6f61aa2",
     "grade": true,
     "grade_id": "cell-f48eb29d8d2e1cfb",
     "locked": true,
     "points": 0.33,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(tfidf_car2), float)\n",
    "assert_equal(type(tfidf_auto2), float)\n",
    "assert_equal(type(tfidf_insurance2), float)\n",
    "assert_equal(type(tfidf_best2), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kD7xVstlSciC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8c5fdb721de76123bcb9ad8bb7a15bb",
     "grade": true,
     "grade_id": "cell-fc354ac597577c33",
     "locked": true,
     "points": 0.33,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(tfidf_car3), float)\n",
    "assert_equal(type(tfidf_auto3), float)\n",
    "assert_equal(type(tfidf_insurance3), float)\n",
    "assert_equal(type(tfidf_best3), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "V3qljwfpSciC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0be7aac3327cc2f8fc85f72a7437790e",
     "grade": false,
     "grade_id": "cell-ec94d8f0b7759e47",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.11 (not graded)\n",
    "\n",
    "Can the tf-idf weight of a term in a document exceed 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CPWM-26SciC"
   },
   "source": [
    "yes it can if the if the term has a high tf like a document with one word let say we have a corpus with 8 documents and the word world is in 2 of them this means we have idf of $\\log(\\frac{8}{2}) = log(4) = 2$ so we have a IDF of 2 and let see if we have a document like \" Hello World world \" now we have tf = $\\frac{2}{3}$ now we have a tf-idf = $\\frac{2}{3} * 2 = \\frac{4}{3}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "h2CL4ZsuSciC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f6eaaa026be91f13e0ce8be96f11ae3",
     "grade": false,
     "grade_id": "cell-ec782620c4d51b67",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.12 (not graded)\n",
    "\n",
    "How does the base of the logarithm in (6.7) affect the score calculation in (6.9)? How does the base of the logarithm affect the relative scores of two documents on a given query?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2wBq6SCwSciD"
   },
   "source": [
    "how higher the log is the closer the numbers will be cause the times a number has to multiply by before it reaches the net big break point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XDofrrJ2SciD",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4350742cb29857ed27e0d72c1f3bf031",
     "grade": false,
     "grade_id": "cell-e7c53f985a1d160a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.13 (not graded)\n",
    "\n",
    "If the logarithm in (6.7) is computed base 2, suggest a simple approximation to the idf of a term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGRizuYqSciD"
   },
   "source": [
    "Computers use base 2 (binary), so by looking at the number of bits that the number needs to be represented, we can make a simple approximation of the idf of a term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1coNMHUfSciD",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d910ee22be99c46c788addb3b5e2982",
     "grade": false,
     "grade_id": "cell-770d1f97e57c370c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.14 (not graded)\n",
    "\n",
    "If we were to stem jealous and jealousy to a common stem before setting up the vector space, detail how the definitions of tf and idf should be modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIRJxROWSciD"
   },
   "source": [
    "the TF would be $tf_{jealous} + tf_{jealousy} = TF_{stemmed \\ jealous}$ but with IDF we can't do the same cause there is a set of documents that both contain jealous and jealousy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "EhmyGnyMSciE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46acbc0edfa0e843e4b2438256e8c6b7",
     "grade": false,
     "grade_id": "cell-2ab77dffbab6471e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.15\n",
    "\n",
    "\"\"Recall the tf-idf weights computed in Exercise 6.10. Compute the Euclidean normalized document vectors for each of the documents, where each vector has four components, one for each of the four terms.\"\"\n",
    "\n",
    "Instead of the question above, make the function `euclidean_normalize(vector)` which normalizes a list (which represents a doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "RfC93QkaSciE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dbcdba750e6906224e41617d08b68db",
     "grade": false,
     "grade_id": "cell-c09bec4374c36b0f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_normalize(vector):\n",
    "  return list(vector/np.linalg.norm(vector))\n",
    "# What test shows that your answer is correct?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "v0dvFtGbSciE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79bc96c8a3f69ceae8a718845b57926f",
     "grade": true,
     "grade_id": "cell-2cb078e3927ebd52",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(euclidean_normalize([tfidf_car3,tfidf_auto3,tfidf_insurance3,tfidf_best3])), list)\n",
    "assert_equal(len(euclidean_normalize([tfidf_car3,tfidf_auto3,tfidf_insurance3,tfidf_best3])), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "21CJ8gwoSciE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea398b414e44d598592771cecb0eb793",
     "grade": false,
     "grade_id": "cell-cddf5cbe2341f988",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.16 (not graded)\n",
    "\n",
    "Verify that the square root of the sum of the squares of the components of each of the document vectors in Exercise 6.15 is 1 (to within rounding error). Why is this the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D4BzQyLjSciF"
   },
   "source": [
    "cause the length of the vector is the $\\sqrt{n_1^2 + n_1^2 + ... + n_x^2}$ so this the length and when we part that menas if you "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Ybkis7U-SciF",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bab33cd60427329fcbcdbfcec3dc9df0",
     "grade": false,
     "grade_id": "cell-d5c97e092bce4d2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.17\n",
    "\n",
    "With term weights as computed in Exercise 6.15, rank the three documents by computed score (using the cosine similarity of the document and the query vector) for the query \"car insurance\", for each of the following cases of term weighting in the query: \n",
    "\n",
    "1. The weight of a term is 1 if present in the query, 0 otherwise. (variable `rank1`)\n",
    "2.  The weight of a term is the idf of that term. (variable `rank2`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "RH35wZPmSciF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae1d1d18a340562c3b3853a9baf722de",
     "grade": false,
     "grade_id": "cell-4a6a0261e6fe0975",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "63d2afa7-6d9c-46ca-c9a7-535881e8d185"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 0, 1, 0], [1.65, 0, 1, 62, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank1=[1,0,1,0]  # list of numbers from 1,2,3\n",
    "rank2=[1.65,0,1,62,0]\n",
    "\n",
    " \n",
    "\n",
    "rank1,rank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Lh8gnlFFSciF",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae4c7f3a50552f77bb09474c68497d1e",
     "grade": true,
     "grade_id": "cell-0409ff7b0d9afc0d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(rank1),list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nX8BL2dDSciG"
   },
   "source": [
    "# Extra theory exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sYFwuSeaSciG",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb1cd8f67689a3d9ed9265539be96d3c",
     "grade": false,
     "grade_id": "isv",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Index size\n",
    "\n",
    "Suppose you have a collection of documents with the following properties:\n",
    "\n",
    "* It has `N` documents.\n",
    "* Each document contains on average `A` many tokens, and `U` many unique tokens.\n",
    "* The vocabulary size of the collection is `V` (this means, that there are `V` many unique words/tokens in the collection.\n",
    "\n",
    "In this question we look at **the size of the posting lists**, when we consider different types of indexes.\n",
    "The size of the posting list is obtained by \"tokenizing\" the posting list. So we ignore separators like comma, and list symbols, etc. For instance, the number of tokens (or the \"length\") of posting `{'d2':(2,[4,18]), 'd8':(1,[7])}` , is 7.\n",
    "\n",
    "Now calculate for each of the following situations the **total number of tokens in the posting lists of the inverted index**.  \n",
    "\n",
    "**For each situation, you should consider the most space efficient index. This means that the index size will grow with each situation described below.**\n",
    "\n",
    "Note the we ask for the size of the posting lists. You do not need to add the space needed for the terms (or termids) themselves.\n",
    "\n",
    "The situations are given in the answer code cell. Give the answer as a formula using the variables declared below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "t5Sc9qzBSciG",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73ade8444e8c2256af7ca08d24955e28",
     "grade": false,
     "grade_id": "isd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "N=100 # number of docs\n",
    "V=8000 # number of unique words in collection\n",
    "A=300  # avg number of words per doc\n",
    "U=100  # avg number of unique words per doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "wb113taUSciH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8148a3a0e5f4dffba82a6af7fc3b678e",
     "grade": false,
     "grade_id": "isa",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "db9a13e0-37f0-4faf-8dd0-00812812c047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "28000\n"
     ]
    }
   ],
   "source": [
    "# size for an index which is suitable for Boolean search (without any form of ranking)\n",
    "BS_index_size = V + U * N \n",
    "\n",
    "\n",
    "print(BS_index_size)\n",
    "\n",
    "# size for an index in which we store for each term  the term-frequency in each document\n",
    "TF_index_size = V + 2 * U * N \n",
    "\n",
    "\n",
    "print(TF_index_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "oUwiQxS2SciH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca776e2d509a6355a875ee5c4268a49e",
     "grade": true,
     "grade_id": "ist",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(BS_index_size,int)\n",
    "\n",
    "# Hier staat een onzichtbare test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "z4kleYMDSciH",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f84f1e4d74fde9b53886f8bcba62678",
     "grade": true,
     "grade_id": "ist-TF",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assert isinstance(TF_index_size,int)\n",
    "# Hier staat een onzichtbare test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6o-ho6xgSciI",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5acad291cb6bf7d14a318fd6d1fb843",
     "grade": false,
     "grade_id": "is2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Index size 2\n",
    "\n",
    "We continue with the numbers from the previous question and add the following.\n",
    "\n",
    "1. 40% of all unique words in the vocabulary occur only once in the whole collection (so once in one document). These are called _hapaxes_.\n",
    "2. On the other hand  2% of all  unique words in the vocabulary occur in at least half of all documents. We call these terms _stopwords_.\n",
    "\n",
    "Now consider the simplest index from the previous question, which is suitable for Boolean Search.\n",
    "\n",
    "1.  How many tokens are there in the posting lists of the hapaxes? (`Hapax_size`)\n",
    "2.  Minimally how many tokens are there in the posting lists of the stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "saLS6NoxSciI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f48b5f3e3b4a3ced6c725006f698382c",
     "grade": false,
     "grade_id": "is2a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "75dfb664-64c7-42fc-ab6b-4e027991f227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200.0\n",
      "160.0\n"
     ]
    }
   ],
   "source": [
    "# How many tokens are there in the posting lists of the hapaxes?\n",
    "\n",
    "Hapax_size = V * 0.4\n",
    "\n",
    "\n",
    "print(Hapax_size)\n",
    "\n",
    "# Minimally how many tokens are there in the posting lists of the stopwords?\n",
    "Stopword_size = V * 0.02\n",
    "\n",
    "\n",
    "print(Stopword_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Z73XMX9hSciI",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f56d1719be820c8eaa078c4995154807",
     "grade": true,
     "grade_id": "is2t",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(Hapax_size,float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Mg5N7cUlSciJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57abb17510ce630bbf783d931b73fe58",
     "grade": true,
     "grade_id": "is2tbis",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(Stopword_size,float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "kM70VyMwSciJ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d49bc59fb629d3c3bd8f187c8c17420",
     "grade": false,
     "grade_id": "cell-0d69e1c149fbb6d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Programming (Inverted Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "y9mDgqq1SciJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e0ac826e7f460ca7197f3e187bd993d",
     "grade": false,
     "grade_id": "cell-6a3911454d0b8cb2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "be0eade6-a97d-4aa3-c4da-f7a77a4f0458"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict,Counter,defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import itertools\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import nltk\n",
    "import zipfile\n",
    "import math\n",
    "import numpy as np\n",
    "def loadShakespeare():\n",
    "    if 'shaks200.zip' in os.listdir():\n",
    "        return 'shaks200.zip'\n",
    "    elif os.path.exists('../../data/Week1/'):\n",
    "        return '../../data/Week1/shaks200.zip'\n",
    "    elif os.path.exists('../../../data/Week1/'):\n",
    "        return '../../../data/Week1/shaks200.zip'\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290
    },
    "id": "qz3U1FnBSciJ",
    "outputId": "ae26ab7b-8acf-40c8-eb5d-6420488dfd78"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-801c60c80d22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../data/Week1/shaks200.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1238\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/Week1/shaks200.zip'"
     ]
    }
   ],
   "source": [
    "zipfile.ZipFile('../../data/Week1/shaks200.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "87f444832e274afebefa5e3bade2fdd5",
      "517be1f205ca4c66a3fb6eec9fc24178",
      "74f187b3560e41a7b3dd4fb3d3b93401",
      "12c538e3221247338a48fc9fae6f24a8",
      "e0d559541dcf496da1e1b0217c595cc3",
      "b380d57f542643fca91f02b9280303ab",
      "9ea494fc5dcf46368b1530164f0fe3db",
      "47abf909689f4f6f9c76d129f0057b69",
      "ff150b08ebd04da5a50ae9b26b86d601",
      "2806502c364d4fafa74887d47e273e61",
      "60aee030939b47be8aec19ca341bf4e4"
     ]
    },
    "deletable": false,
    "id": "LUimGyoISciJ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b79be685015b3e1f2523bc94fa07165",
     "grade": false,
     "grade_id": "cell-512011c182747803",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "4e35159f-1b86-46b1-876a-b5d250e8a36c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f444832e274afebefa5e3bade2fdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Copy your answers to question 1 from week 1 here\"\"\"\n",
    "def index_collection(zipfolder):\n",
    "    # With zipfile we can read the file without opening the zip file\n",
    "    archive = zipfile.ZipFile(zipfolder, 'r')\n",
    "    namelist = [x for x in archive.namelist() if '.xml' in x]\n",
    "    MyIndex = defaultdict(Counter) # initialize MyIndex\n",
    "    for infile in tqdm_notebook(namelist): # loop over each file\n",
    "        f = archive.open(infile)\n",
    "        # Iterate over every word of every doc and add it to the dict\n",
    "        for word in nltk.word_tokenize(BeautifulSoup(f, \"xml\").get_text()):\n",
    "            if word.isalpha():\n",
    "                MyIndex[word.lower()][f.name[:-4]] += 1\n",
    "        \n",
    "    return MyIndex\n",
    "Shakespeare = index_collection(loadShakespeare())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "huDpotpkSciK",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43e99aef339cc287e8b41581bf07b8a8",
     "grade": false,
     "grade_id": "cell-512011c182747803a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Copy your answers to question 3 from week 1 here,\n",
    "So NewIndex will be created\"\"\"\n",
    "CorpusFreq = {key : sum(Shakespeare[str(key)].values()) for key in Shakespeare.keys()}\n",
    "DocFreq = {key : len(Shakespeare[str(key)]) for key in Shakespeare.keys()}\n",
    "NewIndex = {key : {'CorpusFreq' : CorpusFreq[key], 'DocFreq' : DocFreq[key],\n",
    "             'Freq_per_Doc': Shakespeare[key]} for key in Shakespeare.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "id": "Qa1WnvU1SciK",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93809a2f0574d236d7cab7af05633ec2",
     "grade": false,
     "grade_id": "cell-512011c182747803b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Copy your answers to question 3 from week 1 here,\n",
    "So NewIndex[\"TotalFiles\"] will be created\"\"\"\n",
    "\n",
    "NewIndex[\"TotalFiles\"] = set()\n",
    "for value in list(NewIndex.values())[:-1]:\n",
    "    for doc_id in list(value['Freq_per_Doc'].keys()):\n",
    "        NewIndex[\"TotalFiles\"].add(doc_id)\n",
    "        \n",
    "NewIndex[\"TotalFiles\"] = len(NewIndex[\"TotalFiles\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HIl8B3gSciK"
   },
   "outputs": [],
   "source": [
    "# test the schema of NewIndex. For each term, these attributes should be present.\n",
    "assert_equal(set(NewIndex['the'].keys()), {'Freq_per_Doc', 'CorpusFreq', 'DocFreq'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7bMAo3-bSciL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48fb5012e4a15ab1395c196363e05e87",
     "grade": true,
     "grade_id": "cell-0a422d512c7a3d0f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(NewIndex) > 1\n",
    "assert_equal(type(NewIndex[\"TotalFiles\"]), int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KjKD9XulSciL",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e553307753361672a9936ae48fa9189c",
     "grade": false,
     "grade_id": "cell-ce0992093a8a8c20",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 9 Ranked Retrieval\n",
    "\n",
    "In this section we extend the boolean search engine to perform more sophisticated ranked retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7_KBMk10SciL",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1502eea27a546b5195aebe932b56e5d",
     "grade": false,
     "grade_id": "cell-9c893a10d347de93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 9.1 TF-IDF\n",
    "Implement the TF-IDF function 6.8 from the IR -book. So, given a query term $t$ and a document $d$, compute and return the tf-idf$_{t,d}$ score.\n",
    "\n",
    "Note that we use the raw term frequency here, as in the book. Not the log normalized tf as in the slides.\n",
    "\n",
    "**Use logarithm with base 2 in this and all further exercises.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "U06W0ozkSciL",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8499b76c9641d46097b0e0a2b721761",
     "grade": false,
     "grade_id": "cell-0a466ded8aed5c5c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "21eee6ec-7f27-46ee-961e-86f70589c8be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.8378134625158"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf(term, document, index):\n",
    "    \"\"\"\n",
    "    Given a single query term and a document, score the document using\n",
    "    tf-idf.\n",
    "    \"\"\"\n",
    "    if not  index[term]['Freq_per_Doc'][document]:\n",
    "      return 0\n",
    "    tf = index[term]['Freq_per_Doc'][document]\n",
    "    idf = math.log(index['TotalFiles'] / index[term]['DocFreq'], 2)\n",
    "    return tf * idf\n",
    "    \n",
    "tfidf('brutus', 'a_and_c', NewIndex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2Cy9qTJ7SciM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec659575841200d6971c94f78434d4a5",
     "grade": true,
     "grade_id": "cell-e35bc40f7ab55f2f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(tfidf('brutus', 'a_and_c', NewIndex), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zDIy7-DWSciM",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a63208b13a56a27ae1fc6ac6922c6b13",
     "grade": false,
     "grade_id": "cell-167e8d7be386a82e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 9.2 TF-IDF Ranked Search\n",
    "\n",
    "Implement the scoring function 6.9 from the IR -book. So, given a query $Q$ consisting of a list of words, compute for each document the score for this query, and return the document ids and scores in decreasing order.\n",
    "\n",
    "Break ties alphabettically on the doc id (so if docs a and b have the same score a should appear before b).\n",
    "\n",
    "The result is a list of pairs ('docid','score')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "yQSPuHPSSciM",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fd7877e511fdb0a0af3a38006e96220",
     "grade": false,
     "grade_id": "cell-966e28b929230aab",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "00652227-71b0-46a0-c600-039a6d60c52c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('j_caesar', 1108.7171966824924),\n",
       " ('a_and_c', 286.71878474408607),\n",
       " ('coriolan', 240.83041685355556),\n",
       " ('cymbelin', 17.30746533933656),\n",
       " ('hamlet', 4.132505069999679),\n",
       " ('hen_vi_2', 4.132505069999679),\n",
       " ('rich_iii', 3.8461034087414574),\n",
       " ('hen_v', 3.1709792178143146),\n",
       " ('titus', 3.1709792178143146),\n",
       " ('merchant', 2.20945336562895),\n",
       " ('hen_vi_1', 1.9230517043707287),\n",
       " ('hen_vi_3', 1.9230517043707287),\n",
       " ('m_for_m', 1.9230517043707287),\n",
       " ('all_well', 0.9615258521853643),\n",
       " ('as_you', 0.9615258521853643),\n",
       " ('hen_iv_2', 0.9615258521853643),\n",
       " ('lll', 0.9615258521853643),\n",
       " ('m_wives', 0.9615258521853643),\n",
       " ('macbeth', 0.9615258521853643),\n",
       " ('othello', 0.9615258521853643),\n",
       " ('rich_ii', 0.9615258521853643)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rankedSearchTfidf(query,index):\n",
    "    \"\"\"\n",
    "    Given a query, score the documents according to the tf-idf scoring\n",
    "    scheme and return  the documents and scores in decreasing order.\n",
    "    Break ties alphabettically on the doc id (so if docs a and b have the same score a should appear before b)\n",
    "    \"\"\"\n",
    "    out = defaultdict(float)\n",
    "    for term in query:\n",
    "        for document in index[term]['Freq_per_Doc']:\n",
    "            out[document] = out[document] + tfidf(term,document,index)\n",
    "    out = list(out.items())\n",
    "    out.sort(key=lambda x:x[1], reverse=True)\n",
    "    return out\n",
    "    \n",
    "rankedSearchTfidf(['brutus', 'caesar'], NewIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MJpayOwsSciN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0fb1eb12ec132a8c00e05c5b1cf1b6e",
     "grade": true,
     "grade_id": "cell-1ca47df9d70de0ed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result = rankedSearchTfidf(['brutus','caesar'], NewIndex)\n",
    "assert_equal(type(result),list)\n",
    "assert_equal(type(result[0]),tuple)\n",
    "assert_equal(type(result[0][0]),str)\n",
    "assert isinstance(result[0][1],float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Lort0ycCSciN",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85a361c8618ed3f3b187af5e32c4dc5f",
     "grade": false,
     "grade_id": "cell-46fab5262171c652",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 9.3 Vector Space Model\n",
    "\n",
    "We now want to implement the cosine similarity function. To do this we need to vectorize documents and normalize them. We use Euclidean length for that (see section 6.3). Create a function that can vectorize and normalize a document:\n",
    "\n",
    "$normalizedVector(d) = \\frac{V(d)}{|V(d)|}$\n",
    "\n",
    "* Make sure you don't take `TotalFiles` as a word\n",
    "* Include all words in the corpus, even if they are not in document (so they will be 0)\n",
    "* Make sure you sort the words alphabetically\n",
    "* the value for each term is its TF-IDF weight as calculated by your earlier `tfidf` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "grGwvu2hSciN",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71013f66dc1212be5cc0a4f483e9d10a",
     "grade": false,
     "grade_id": "cell-c9694a0ad4a895c6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "574dc36c-1554-46c5-8003-bcc2fc730e9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22328, [0.0, 0.0, 0.0, 0.0, 0.0028840469429352866])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizedVector(document, index):\n",
    "    \"\"\"\n",
    "    Given a document, vectorize and normalize it\n",
    "    \"\"\"\n",
    "    out = [tfidf(term, document, index) for term in sorted(list(index.keys())[:-1])]\n",
    "    return euclidean_normalize(out)\n",
    "    \n",
    "len(normalizedVector('all_well', NewIndex)), normalizedVector('all_well', NewIndex)[:5]\n",
    "\n",
    "# Check that the Euclidean length of your vector equals 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Wp8aO__hSciO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "401805946e2c5af0a0a2ede6f43bbc1e",
     "grade": true,
     "grade_id": "cell-2e8497964ac87a83",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(normalizedVector('all_well', NewIndex)), len(NewIndex)-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "gdRATrsYSciO",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "022cc4171dc22326a8ad75e66d323bf3",
     "grade": false,
     "grade_id": "cell-bc303ce875aa2bcf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 9.4 Cosine Similarity\n",
    "\n",
    "Use the normalized lengths to compute the cosine-similarity between a query and a document. I.e. implement scoring formula 6.12 from the book.\n",
    "\n",
    "Do this in the form of the function `cosineSimilarity(query, document, index)`\n",
    "\n",
    "The query vector is a boolean vector with the value for a term being 1 if and only if it occurs at least once in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "y92ytWcmSciO",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8138b0030c003559ec4bbbf63ffa07f5",
     "grade": false,
     "grade_id": "cell-a87cb124f00cdf2e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "4e4a4079-f197-42dc-ac81-01dd486bffad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0029940539138864973"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosineSimilarity(query, document, index):\n",
    "    \"\"\"\n",
    "    Given a query and a document, compute and return the cosine-similarity\n",
    "    between the two.\n",
    "    \"\"\"\n",
    "    qvector = euclidean_normalize([1 if key in query else 0 for key in sorted(list(index.keys())[:-1])])\n",
    "    dvector = normalizedVector(document, index)\n",
    "    return np.dot(qvector, dvector)\n",
    "    \n",
    "cosineSimilarity(['brutus','love'], 'a_and_c', NewIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "cml58TdFSciP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3303339d40025d69d7d04f4fb7e26a2",
     "grade": true,
     "grade_id": "cell-c960058b3d6d3183",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(cosineSimilarity(['love','lightly'], 'all_well', NewIndex)) in [float, np.float64, np.float32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RvdyxaE6SciP",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22bfcf588c705a82d7e07222d84759e2",
     "grade": false,
     "grade_id": "cell-9c5c306eae897889",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 9.5 Okapi BM25\n",
    "Now create a search engine which scores according to another famous scoring formula [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "WVA2dYyoSciP",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a543ac97d16ad6fa14d1bdc3046bc3ba",
     "grade": false,
     "grade_id": "cell-236a53b720ae81a9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "3c9c923e-5537-449d-d0d7-9a5e4d7caabc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brutus\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('j_caesar', 5.499730851193349),\n",
       " ('coriolan', 5.458626859324228),\n",
       " ('a_and_c', 4.109740121715352),\n",
       " ('hamlet', 2.4946556692411903),\n",
       " ('hen_v', 2.3457365256047558),\n",
       " ('hen_vi_2', 2.322934341467456),\n",
       " ('merchant', 2.1355641732578703),\n",
       " ('titus', 2.1157005362512553)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def rankedSearchBM25(query, index, a=1.5, b=0.75):\n",
    "    \"\"\"\n",
    "    Given a query, score the documents according to the BM25 scoring\n",
    "    scheme and return a list of  (document, score) pairs  in decreasing order\n",
    "    \"\"\"\n",
    "    # this get data on all data for all files\n",
    "    docinfo = defaultdict(int)\n",
    "    for word in index.keys():\n",
    "      if type(index[word]) != int:\n",
    "        for (doc,num) in  index[word]['Freq_per_Doc'].items():\n",
    "          docinfo[doc] = docinfo[doc] + num\n",
    "\n",
    "    doc_avg  = np.average(list(docinfo.values()))\n",
    "\n",
    "    ans = defaultdict(float)\n",
    "    for word in query:\n",
    "      print(word)\n",
    "      if word not in index.keys():\n",
    "        continue\n",
    "      for document in index[word]['Freq_per_Doc']:\n",
    "\n",
    "          # this the top part of the equation of ranked BM25 search.\n",
    "          tempValue = tfidf(word,document,index) * (a + 1)\n",
    "          #this is the down part of the equation\n",
    "          tempDown = doc_avg / docinfo[document]\n",
    "          tempDown = index[word]['Freq_per_Doc'][document] + a * (1 - b + b * tempDown)\n",
    "          ans [document] = ans[document] + tempValue / tempDown\n",
    "\n",
    "\n",
    "    ans = list(ans.items())\n",
    "    ans.sort(key = lambda x:x[1], reverse= True)\n",
    "    return ans\n",
    "\n",
    "    \n",
    "rankedSearchBM25(['brutus'], NewIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "hX9zTiJmSciQ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "096ddb7cfd35f4291a2b3a2edaca9889",
     "grade": true,
     "grade_id": "cell-860fbb8c8bd77a2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "d17dc05c-bfe0-4182-de77-4c9fd764ec0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.109740121715352\n",
      "5.458626859324228\n",
      "2.4946556692411903\n",
      "2.3457365256047558\n",
      "2.322934341467456\n",
      "5.499730851193349\n",
      "2.1355641732578703\n",
      "2.1157005362512553\n"
     ]
    }
   ],
   "source": [
    "result = rankedSearchBM25(['brutus'], NewIndex)\n",
    "assert_equal(type(result),list)\n",
    "assert_equal(type(result[0]),tuple)\n",
    "assert_equal(type(result[0][0]),str)\n",
    "assert isinstance(result[0][1],float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M25YK7-JSciQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AssignmentWeek2.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "12c538e3221247338a48fc9fae6f24a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff150b08ebd04da5a50ae9b26b86d601",
      "max": 37,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47abf909689f4f6f9c76d129f0057b69",
      "value": 37
     }
    },
    "2806502c364d4fafa74887d47e273e61": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "47abf909689f4f6f9c76d129f0057b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "517be1f205ca4c66a3fb6eec9fc24178": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60aee030939b47be8aec19ca341bf4e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74f187b3560e41a7b3dd4fb3d3b93401": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ea494fc5dcf46368b1530164f0fe3db",
      "placeholder": "​",
      "style": "IPY_MODEL_b380d57f542643fca91f02b9280303ab",
      "value": "100%"
     }
    },
    "87f444832e274afebefa5e3bade2fdd5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_74f187b3560e41a7b3dd4fb3d3b93401",
       "IPY_MODEL_12c538e3221247338a48fc9fae6f24a8",
       "IPY_MODEL_e0d559541dcf496da1e1b0217c595cc3"
      ],
      "layout": "IPY_MODEL_517be1f205ca4c66a3fb6eec9fc24178"
     }
    },
    "9ea494fc5dcf46368b1530164f0fe3db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b380d57f542643fca91f02b9280303ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0d559541dcf496da1e1b0217c595cc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60aee030939b47be8aec19ca341bf4e4",
      "placeholder": "​",
      "style": "IPY_MODEL_2806502c364d4fafa74887d47e273e61",
      "value": " 37/37 [00:15&lt;00:00,  2.53it/s]"
     }
    },
    "ff150b08ebd04da5a50ae9b26b86d601": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
