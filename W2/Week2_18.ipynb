{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_3DDFr0osRd"
   },
   "source": [
    "# Zoekmachines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTerJDzBosRl"
   },
   "source": [
    "## Notebook made by\n",
    "\n",
    "__Name__|Job| en vrienden\n",
    "\n",
    "__Student id__ : secret - secret - secret - secret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4br1aV-osRo"
   },
   "source": [
    "## Toelichting\n",
    "\n",
    "* De meeste opgaven worden automatisch nagekeken. Bij vrijwel alle opdrachten staan er een paar zichtbare tests onder de opdracht, dit is voornamelijk om te zorgen dat je de juiste type output geeft. De andere tests worden na inleveren toegevoegd aan die cell.\n",
    "\n",
    "## Voor het inleveren!\n",
    "\n",
    "* Pas niet de cellen aan, vooral niet die je niet kunt editen. Dit levert problemen op bij nakijken. Twijfel je of je per ongeluk iets hebt gewijzigd, kopieer dan bij inleveren je antwoorden naar een nieuw bestand, zodat het niet fout kan gaan.\n",
    "\n",
    "* Zorg dat de code goed runt van boven naar beneden, verifieer dat door boven in Kernel -> Restart & Run All uit te voeren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPJQOHvhosRr",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Week-2\" data-toc-modified-id=\"Week-2-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Week 2</a></span></li><li><span><a href=\"#Book-exercises\" data-toc-modified-id=\"Book-exercises-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Book exercises</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#2.1\" data-toc-modified-id=\"2.1-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>2.1</a></span></li><li><span><a href=\"#2.2-(not-graded)\" data-toc-modified-id=\"2.2-(not-graded)-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>2.2 (not graded)</a></span></li><li><span><a href=\"#2.3\" data-toc-modified-id=\"2.3-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>2.3</a></span></li><li><span><a href=\"#2.4-(not-graded)\" data-toc-modified-id=\"2.4-(not-graded)-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>2.4 (not graded)</a></span></li><li><span><a href=\"#2.8-(not-graded)\" data-toc-modified-id=\"2.8-(not-graded)-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>2.8 (not graded)</a></span></li><li><span><a href=\"#2.9\" data-toc-modified-id=\"2.9-2.0.6\"><span class=\"toc-item-num\">2.0.6&nbsp;&nbsp;</span>2.9</a></span></li><li><span><a href=\"#2.10\" data-toc-modified-id=\"2.10-2.0.7\"><span class=\"toc-item-num\">2.0.7&nbsp;&nbsp;</span>2.10</a></span></li><li><span><a href=\"#6.9\" data-toc-modified-id=\"6.9-2.0.8\"><span class=\"toc-item-num\">2.0.8&nbsp;&nbsp;</span>6.9</a></span></li><li><span><a href=\"#6.10\" data-toc-modified-id=\"6.10-2.0.9\"><span class=\"toc-item-num\">2.0.9&nbsp;&nbsp;</span>6.10</a></span></li><li><span><a href=\"#6.11-(not-graded)\" data-toc-modified-id=\"6.11-(not-graded)-2.0.10\"><span class=\"toc-item-num\">2.0.10&nbsp;&nbsp;</span>6.11 (not graded)</a></span></li><li><span><a href=\"#6.12-(not-graded)\" data-toc-modified-id=\"6.12-(not-graded)-2.0.11\"><span class=\"toc-item-num\">2.0.11&nbsp;&nbsp;</span>6.12 (not graded)</a></span></li><li><span><a href=\"#6.13-(not-graded)\" data-toc-modified-id=\"6.13-(not-graded)-2.0.12\"><span class=\"toc-item-num\">2.0.12&nbsp;&nbsp;</span>6.13 (not graded)</a></span></li><li><span><a href=\"#6.14-(not-graded)\" data-toc-modified-id=\"6.14-(not-graded)-2.0.13\"><span class=\"toc-item-num\">2.0.13&nbsp;&nbsp;</span>6.14 (not graded)</a></span></li><li><span><a href=\"#6.15\" data-toc-modified-id=\"6.15-2.0.14\"><span class=\"toc-item-num\">2.0.14&nbsp;&nbsp;</span>6.15</a></span></li><li><span><a href=\"#6.16-(not-graded)\" data-toc-modified-id=\"6.16-(not-graded)-2.0.15\"><span class=\"toc-item-num\">2.0.15&nbsp;&nbsp;</span>6.16 (not graded)</a></span></li><li><span><a href=\"#6.17\" data-toc-modified-id=\"6.17-2.0.16\"><span class=\"toc-item-num\">2.0.16&nbsp;&nbsp;</span>6.17</a></span></li></ul></li></ul></li><li><span><a href=\"#Extra-theory-exercises\" data-toc-modified-id=\"Extra-theory-exercises-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Extra theory exercises</a></span><ul class=\"toc-item\"><li><span><a href=\"#Index-size\" data-toc-modified-id=\"Index-size-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Index size</a></span></li><li><span><a href=\"#Index-size-2\" data-toc-modified-id=\"Index-size-2-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Index size 2</a></span></li></ul></li><li><span><a href=\"#Programming-(Inverted-Index)\" data-toc-modified-id=\"Programming-(Inverted-Index)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Programming (Inverted Index)</a></span><ul class=\"toc-item\"><li><span><a href=\"#9-Ranked-Retrieval\" data-toc-modified-id=\"9-Ranked-Retrieval-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>9 Ranked Retrieval</a></span></li><li><span><a href=\"#9.1-TF-IDF\" data-toc-modified-id=\"9.1-TF-IDF-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>9.1 TF-IDF</a></span><ul class=\"toc-item\"><li><span><a href=\"#9.2-TF-IDF-Ranked-Search\" data-toc-modified-id=\"9.2-TF-IDF-Ranked-Search-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>9.2 TF-IDF Ranked Search</a></span></li><li><span><a href=\"#9.3-Vector-Space-Model\" data-toc-modified-id=\"9.3-Vector-Space-Model-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>9.3 Vector Space Model</a></span></li><li><span><a href=\"#9.4-Cosine-Similarity\" data-toc-modified-id=\"9.4-Cosine-Similarity-4.2.3\"><span class=\"toc-item-num\">4.2.3&nbsp;&nbsp;</span>9.4 Cosine Similarity</a></span></li><li><span><a href=\"#9.5-Okapi-BM25\" data-toc-modified-id=\"9.5-Okapi-BM25-4.2.4\"><span class=\"toc-item-num\">4.2.4&nbsp;&nbsp;</span>9.5 Okapi BM25</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Xdvl-xYSosRt",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b9fbfec4f0391fb1311b40615454a2b4",
     "grade": false,
     "grade_id": "cell-d32efc5c56bf7199",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "editable": false,
    "id": "_ffXv8lxosRu",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "630bc803cc5920da4bbaf276dc195f58",
     "grade": false,
     "grade_id": "cell-e86d56c9ad0aa4e5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    },
    "outputId": "ac8ec4b2-4a58-434f-f014-630ebb61f196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (1.3.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install nose\n",
    "from nose.tools import assert_equal, assert_almost_equal\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "c_LL1qIIosRw",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96b23d353367523fb2e238baade2a528",
     "grade": false,
     "grade_id": "cell-2ea109d597cac3d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Book exercises\n",
    "In this section you will make the exercises from the book, which is freely available online as a PDF at [nlp.stanford.edu/IR-book/](http://nlp.stanford.edu/IR-book/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "id": "baz5iRFWosRw",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ec04407cf35c76af81cd3c58077931e",
     "grade": false,
     "grade_id": "cell-675cbcb22f189c5c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1\n",
    "\n",
    "Are the following statements true or false?\n",
    "\n",
    "a. In a Boolean retrieval system, stemming never lowers precision.\n",
    "\n",
    "b. In a Boolean retrieval system, stemming never lowers recall.\n",
    "\n",
    "c. Stemming increases the size of the vocabulary.\n",
    "\n",
    "d. Stemming should be invoked at indexing time but not while processing a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "BwkBvW9ZosRx",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae72a753a09a3a013f5996e05006eb61",
     "grade": false,
     "grade_id": "cell-9fba209db4797a78",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "bb8490e7-7f90-46f7-8f1d-e8e37ce90e04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False, False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = False \n",
    "b = True \n",
    "c = False\n",
    "d = False\n",
    "\n",
    "\n",
    "a, b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JxBFlevbosR1",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8cb829764eefb004110c89bab32200fc",
     "grade": true,
     "grade_id": "cell-fc1c070acbfa02f6",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(a), bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4foNqarGosR2",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "327b6613bdaacdfccd7bd248a97c9a0c",
     "grade": true,
     "grade_id": "cell-323357d08fec7701",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(b), bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "r7SuZiHDosR3",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a287baf29f0d2f5fe3b29633eba3ce57",
     "grade": true,
     "grade_id": "cell-8d2d64004b40ab52",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(c), bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "K7rsGM0yosR4",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63a327b74f2cf3d55a4e51bac0649b73",
     "grade": true,
     "grade_id": "cell-e3f19c4c556a014a",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(d), bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "YPLsY2cAosR5",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f064953d97ee1b4f32ee659132409aea",
     "grade": false,
     "grade_id": "cell-e823f1efc7adcaba",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.2 (not graded)\n",
    "\n",
    "Suggest what normalized form should be used for these words (including the word\n",
    "itself as a possibility):\n",
    "1. ’Cos\n",
    "2. Shi’ite\n",
    "3. cont’d\n",
    "4. Hawai’i\n",
    "5. O’Rourke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Hrf1RdpnosR6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "82b6952dc64bcf927f866b4df73312fa",
     "grade": false,
     "grade_id": "cell-3eb40501c393b362",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "a) 'Cos: cos (Because the number of Google results for Cos , Cos ,cos and cos are exactly same.)<br/>\n",
    "b) Shi'ite: shiite (Because on Google, shiite gives more results than shi-ite)<br/>\n",
    "c) cont'd: contd<br/>\n",
    "d) Hawai'i: hawaii (Hawai'i, hawai'i, Hawaii)<br/>\n",
    "e) O'Rourke: orourke (O'Rourke, o'rourke, ORourke)<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HcY_yK7uosR6",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9cc4f86fae84ee0f7e3aad6ad19051e2",
     "grade": false,
     "grade_id": "cell-3d752b81075d9d59",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.3\n",
    "\n",
    "The following pairs of words are stemmed to the same form by the Porter stemmer.\n",
    "Which pairs would you argue shouldn’t be conflated. Give your reasoning.\n",
    "1. abandon/abandonment\n",
    "2. absorbency/absorbent\n",
    "3. marketing/markets\n",
    "4. university/universe\n",
    "5. volume/volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "id": "mLC31as-osR7",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "981ce4c849ceb781660368b32e8a0bd1",
     "grade": false,
     "grade_id": "203",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "should=set([1, 2]) # answer as a set of numbers between 1 and 5\n",
    "shouldnot=set([3, 4, 5])\n",
    "\n",
    "# The words in 1 and 2 basically have the same meaning and are mostly morphologically distinct. \n",
    "# The words in 3, 4 and 5 have significantly different meanings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qxbVS7XXosR8",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bc83af6df0a6e08d08edea1405387b17",
     "grade": true,
     "grade_id": "203-t",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(should), set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5Q3f7kuiosR8",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f68eae612fde17e8990a052accdf0ca",
     "grade": false,
     "grade_id": "cell-bed75dda3272a6ec",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.4 (not graded)\n",
    "\n",
    "For the Porter stemmer rule group shown in (2.1):\n",
    "1. What is the purpose of including an identity rule such as SS → SS?\n",
    "2. Applying just this rule group, what will the following words be stemmed to?\n",
    "   > _circus_ _canaries_ _boss_\n",
    "3. What rule should be added to correctly stem pony?\n",
    "4. The stemming for ponies and pony might seem strange. Does it have a deleterious effect on retrieval? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2dlHCU1osR9",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fffd9e79acf9c04c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "1. The purpose of including an identity such as SS->SS is to prevent the wrong stemming of words like caress using the rule s->nothing.\n",
    "2. circus->circu, canaries->canari, boss->boss\n",
    "3. y->i\n",
    "4. When combining ponies and pony you will get more documents when requesting either one of the terms. So it will not have a deleterious effect on retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "apwyEVP7osR9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "06c9a4bf72abdd34619bd5aabb16ac7f",
     "grade": false,
     "grade_id": "cell-e69cd0806b78c2e5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.8 (not graded)\n",
    "\n",
    "Assume a biword index. Give an example of a document which will be returned\n",
    "for a query of New York University but is actually a false positive which should not be\n",
    "returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDDs6R-AosR9",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48f9c4a70c356cb9",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Research on New York, done at York University."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FPNya6fiosR9",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7552f71351167a476319e9900fb1796",
     "grade": false,
     "grade_id": "cell-63f4fe400c5affd4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.9\n",
    "\n",
    "Shown below is a portion of a positional index in the format:\n",
    "> term: doc1: $\\langle$ position1, position2, . . . $\\rangle$; doc2: $\\langle$ position1, position2, . . .$\\rangle$; etc.\n",
    "\n",
    "angels: 2: $\\langle$36,174,252,651$\\rangle$; 4: $\\langle$12,22,102,432$\\rangle$; 7: $\\langle$17$\\rangle$;<br/>\n",
    "fools: 2: $\\langle$1,17,74,222$\\rangle$; 4: $\\langle$8,78,108,458$\\rangle$; 7: $\\langle$3,13,23,193$\\rangle$;<br/>\n",
    "fear: 2: $\\langle$87,704,722,901$\\rangle$; 4: $\\langle$13,43,113,433$\\rangle$; 7: $\\langle$18,328,528$\\rangle$;<br/>\n",
    "in: 2: $\\langle$3,37,76,444,851$\\rangle$; 4: $\\langle$10,20,110,470,500$\\rangle$; 7: $\\langle$5,15,25,195$\\rangle$;<br/>\n",
    "rush: 2: $\\langle$2,66,194,321,702$\\rangle$; 4: $\\langle$9,69,149,429,569$\\rangle$; 7: $\\langle$4,14,404$\\rangle$;<br/>\n",
    "to: 2: $\\langle$47,86,234,999$\\rangle$; 4: $\\langle$14,24,774,944$\\rangle$; 7: $\\langle$199,319,599,709$\\rangle$;<br/>\n",
    "tread: 2: $\\langle$57,94,333$\\rangle$; 4: $\\langle$15,35,155$\\rangle$; 7: $\\langle$20,320$\\rangle$;<br/>\n",
    "where: 2: $\\langle$67,124,393,1001$\\rangle$; 4: $\\langle$11,41,101,421,431$\\rangle$; 7: $\\langle$16,36,736$\\rangle$;\n",
    "\n",
    "Which document(s) if any match each of the following queries, where each expression\n",
    "within quotes is a phrase query?\n",
    "1. “fools rush in”\n",
    "2. “fools rush in” AND “angels fear to tread”\n",
    "\n",
    "Give your answer as sets, respectively `firstphrase` and `secondphrase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "id": "D4ORSuj6osR_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5638f028b98c5844bbe4becee9425436",
     "grade": false,
     "grade_id": "cell-04b90595b2cf07b8",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "firstphrase = set([2, 4, 7])\n",
    "secondphrase = set([4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dxVNgNNuosR_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1bdc3f6d488713b88e2bf9b42027bdfe",
     "grade": true,
     "grade_id": "cell-32f1ec171801d213",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(firstphrase),set)\n",
    "assert_equal(type(secondphrase),set)\n",
    "for x in firstphrase:\n",
    "    assert x in [2,4,7]\n",
    "for x in secondphrase:\n",
    "    assert x in [2,4,7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "id": "T_UFAXeeosSA",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c48da0d0d660996de269fe685bd474a9",
     "grade": false,
     "grade_id": "cell-fc519c5fe85e638a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.10\n",
    "\n",
    "Consider the following fragment of a positional index with the format:\n",
    "\n",
    "> word: document: $\\langle$position, position, . . .$\\rangle$; document: $\\langle$position, . . .$\\rangle$<br />\n",
    ". . .\n",
    "\n",
    ">Gates: 1: $\\langle$3$\\rangle$; 2: $\\langle$6$\\rangle$; 3: $\\langle$2,17$\\rangle$; 4: $\\langle$1$\\rangle$;<br />\n",
    "IBM: 4: $\\langle$3$\\rangle$; 7: $\\langle$14$\\rangle$;<br />\n",
    "Microsoft: 1: $\\langle$1$\\rangle$; 2: $\\langle$1,21$\\rangle$; 3: $\\langle$3$\\rangle$; 5: $\\langle$16,22,51$\\rangle$;\n",
    "\n",
    "The $/k$ operator, word1 $/k$ word2 finds occurrences of word1 within $k$ words of word2 (on either side), where $k$ is a positive integer argument. Thus $k = 1$ demands that word1 be adjacent to word2.\n",
    "1. Describe the set of documents that satisfy the query Gates $/2$ Microsoft.\n",
    "2. Describe for each value  $k$ between 1 and 7 the set of documents returned after the   query Gates $/k$ Microsoft.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "id": "uMkWVbWlosSA",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f3e1268104f09f866b5290e9886c935e",
     "grade": false,
     "grade_id": "cell-31e611774e33399f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "k1 = set([3])\n",
    "k2 = set([1,3])\n",
    "k3 = set([1,3])\n",
    "k4 = set([1,3])\n",
    "k5 = set([1,2,3])\n",
    "k6 = set([1,2,3])\n",
    "k7 = set([1,2,3])\n",
    "# docID (p1), pos (pp1), ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yKKgbm8UosSA",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d58a744476a8966380e5a06b66215d23",
     "grade": true,
     "grade_id": "cell-b933f7947f3f78db",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for k in [k1,k2,k3,k4,k5,k6,k7]:\n",
    "    assert_equal(type(k),set)\n",
    "    assert k.issubset({1,2,3,4,5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1ASBqNZQosSB",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aa8ce28acd7139228b14cc498761066c",
     "grade": false,
     "grade_id": "cell-28339956b6d5bd88",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.9\n",
    "\n",
    "What is the idf of a term that occurs in every document (variable `idf_every_doc`)? Compare this with the use of stop word lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "id": "uOhqZ6u2osSB",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d81786146a40dce3fa159fe47f00d450",
     "grade": false,
     "grade_id": "cell-84323557f1b57844",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "idf_every_doc = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "IO5jrGx-osSC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ff52eb8374fc8ae787529b4d72debc1",
     "grade": true,
     "grade_id": "cell-3cbf108756459c24",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(idf_every_doc) in [int, float]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "y-xTTg6DosSC",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d0800b3534752364a4c5ab17e61e9220",
     "grade": false,
     "grade_id": "cell-614376aa2b170562",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.10\n",
    "\n",
    "Consider the table of term frequencies for 3 documents denoted Doc1, Doc2, Doc3 in Figure 6.9. Compute the tf-idf weights for the terms car, auto, insurance, best, for each document, using the idf values from Figure 6.8.\n",
    "\n",
    "Note that we use tf-idf weighting **with the raw tf values** in this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "3fHz22J2osSC",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "98647192fe173f6c177c5a75e2e8077e",
     "grade": false,
     "grade_id": "cell-3753d6674d83ae0e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "6980e9a9-27c8-46c6-a41a-5a5ab38d5cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc1: [44.55, 6.24, 0.0, 21.0]\n",
      "Doc2: [6.6, 68.64, 53.46, 0.0]\n",
      "Doc3: [39.599999999999994, 0.0, 46.980000000000004, 25.5]\n"
     ]
    }
   ],
   "source": [
    "# for Doc1\n",
    "tfidf_car1 = 27 * 1.65\n",
    "tfidf_auto1 = 3 * 2.08\n",
    "tfidf_insurance1 = 0 * 1.62\n",
    "tfidf_best1 =  14 * 1.5\n",
    "# for Doc2\n",
    "tfidf_car2 = 4 * 1.65\n",
    "tfidf_auto2 = 33 * 2.08\n",
    "tfidf_insurance2 = 33 * 1.62\n",
    "tfidf_best2 =  0 * 1.5\n",
    "# for Doc3\n",
    "tfidf_car3 = 24 * 1.65\n",
    "tfidf_auto3 = 0 * 2.08\n",
    "tfidf_insurance3 = 29 * 1.62\n",
    "tfidf_best3 =  17 * 1.5\n",
    "\n",
    "\n",
    "print(\"Doc1: [%s, %s, %s, %s]\" %(tfidf_car1, tfidf_auto1, tfidf_insurance1, tfidf_best1))\n",
    "print(\"Doc2: [%s, %s, %s, %s]\" %(tfidf_car2, tfidf_auto2, tfidf_insurance2, tfidf_best2))\n",
    "print(\"Doc3: [%s, %s, %s, %s]\" %(tfidf_car3, tfidf_auto3, tfidf_insurance3, tfidf_best3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UcmJs5KkosSD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a86bb42f5fc40279545c5c5000b8e847",
     "grade": true,
     "grade_id": "cell-d465a3ce0a126ca9",
     "locked": true,
     "points": 0.34,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(tfidf_car1), float)\n",
    "assert_equal(type(tfidf_auto1), float)\n",
    "assert_equal(type(tfidf_insurance1), float)\n",
    "assert_equal(type(tfidf_best1), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RlKx9wzWosSD",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6df9c1f94026f853ad109c41c6f61aa2",
     "grade": true,
     "grade_id": "cell-f48eb29d8d2e1cfb",
     "locked": true,
     "points": 0.33,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(tfidf_car2), float)\n",
    "assert_equal(type(tfidf_auto2), float)\n",
    "assert_equal(type(tfidf_insurance2), float)\n",
    "assert_equal(type(tfidf_best2), float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "obaKTpBrosSE",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8c5fdb721de76123bcb9ad8bb7a15bb",
     "grade": true,
     "grade_id": "cell-fc354ac597577c33",
     "locked": true,
     "points": 0.33,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(tfidf_car3), float)\n",
    "assert_equal(type(tfidf_auto3), float)\n",
    "assert_equal(type(tfidf_insurance3), float)\n",
    "assert_equal(type(tfidf_best3), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "W3nm5X62osSE",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0be7aac3327cc2f8fc85f72a7437790e",
     "grade": false,
     "grade_id": "cell-ec94d8f0b7759e47",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.11 (not graded)\n",
    "\n",
    "Can the tf-idf weight of a term in a document exceed 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEdhxZ9IosSE"
   },
   "source": [
    "Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eGSEHdAnosSU",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8f6eaaa026be91f13e0ce8be96f11ae3",
     "grade": false,
     "grade_id": "cell-ec782620c4d51b67",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.12 (not graded)\n",
    "\n",
    "How does the base of the logarithm in (6.7) affect the score calculation in (6.9)? How does the base of the logarithm affect the relative scores of two documents on a given query?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CY3X_1_mosSW"
   },
   "source": [
    "No, log(1) is always 0, regardless of base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7neYbvfMosSX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4350742cb29857ed27e0d72c1f3bf031",
     "grade": false,
     "grade_id": "cell-e7c53f985a1d160a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.13 (not graded)\n",
    "\n",
    "If the logarithm in (6.7) is computed base 2, suggest a simple approximation to the idf of a term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HtpjlyQqosSX"
   },
   "source": [
    "This is possible by computing the Taylor approximation up to a certain degree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "NIFRnTklosSX",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2d910ee22be99c46c788addb3b5e2982",
     "grade": false,
     "grade_id": "cell-770d1f97e57c370c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.14 (not graded)\n",
    "\n",
    "If we were to stem jealous and jealousy to a common stem before setting up the vector space, detail how the definitions of tf and idf should be modified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sSFNqM4OosSY"
   },
   "source": [
    "The tf's of both words can be summed together.\n",
    "\n",
    "The df should be modified to count the documents holding jealous and jealousy. This is not a simple addition. Afterwards the idf should be recalculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "M5LI2UkrosSY",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46acbc0edfa0e843e4b2438256e8c6b7",
     "grade": false,
     "grade_id": "cell-2ab77dffbab6471e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.15\n",
    "\n",
    "\"\"Recall the tf-idf weights computed in Exercise 6.10. Compute the Euclidean normalized document vectors for each of the documents, where each vector has four components, one for each of the four terms.\"\"\n",
    "\n",
    "Instead of the question above, make the function `euclidean_normalize(vector)` which normalizes a list (which represents a doc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "PRd1OkzeosSY",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4dbcdba750e6906224e41617d08b68db",
     "grade": false,
     "grade_id": "cell-c09bec4374c36b0f",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "6e44e583-88e2-49fe-e068-3e708b625665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5952679795256183, 0.0, 0.7062042848008473, 0.38331650196725425]\n"
     ]
    }
   ],
   "source": [
    "def euclidean_normalize(vector):\n",
    "    return list(vector / np.sqrt(np.sum(np.array(vector)**2)))\n",
    "    \n",
    "x=euclidean_normalize([tfidf_car3,tfidf_auto3,tfidf_insurance3,tfidf_best3])\n",
    "print(x)\n",
    "# What test shows that your answer is correct?\n",
    "assert_almost_equal(1., np.sqrt(np.sum(np.array(x)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "QNQGQD23osSZ",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79bc96c8a3f69ceae8a718845b57926f",
     "grade": true,
     "grade_id": "cell-2cb078e3927ebd52",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(euclidean_normalize([tfidf_car3,tfidf_auto3,tfidf_insurance3,tfidf_best3])), list)\n",
    "assert_equal(len(euclidean_normalize([tfidf_car3,tfidf_auto3,tfidf_insurance3,tfidf_best3])), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ryikBztNosSZ",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ea398b414e44d598592771cecb0eb793",
     "grade": false,
     "grade_id": "cell-cddf5cbe2341f988",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.16 (not graded)\n",
    "\n",
    "Verify that the square root of the sum of the squares of the components of each of the document vectors in Exercise 6.15 is 1 (to within rounding error). Why is this the case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "9Gwfqq-7osSa"
   },
   "outputs": [],
   "source": [
    "doc1 = [tfidf_car1, tfidf_auto1, tfidf_insurance1, tfidf_best1]\n",
    "doc2 = [tfidf_car2, tfidf_auto2, tfidf_insurance2, tfidf_best2]\n",
    "doc3 = [tfidf_car3, tfidf_auto3, tfidf_insurance3, tfidf_best3]\n",
    "\n",
    "for vec in [doc1, doc2, doc3]:\n",
    "    assert_almost_equal(1., np.sqrt(np.sum(np.array(euclidean_normalize(vec))**2)))\n",
    "    \n",
    "# Because these vectors are now normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "S5KpSukmosSa",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bab33cd60427329fcbcdbfcec3dc9df0",
     "grade": false,
     "grade_id": "cell-d5c97e092bce4d2a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 6.17\n",
    "\n",
    "With term weights as computed in Exercise 6.15, rank the three documents by computed score (using the cosine similarity of the document and the query vector) for the query \"car insurance\", for each of the following cases of term weighting in the query: \n",
    "\n",
    "1. The weight of a term is 1 if present in the query, 0 otherwise. (variable `rank1`)\n",
    "2.  The weight of a term is the idf of that term. (variable `rank2`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t46xVvGsxisu",
    "outputId": "5ec46c84-bb9b-4c64-f62b-791edb11f562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8973687741434395\n",
      "0.6883478324628158\n",
      "1.3014722643264656\n",
      "1.480658477336675\n",
      "1.1173927671583204\n",
      "2.1262431075946426\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3, 1, 2], [3, 1, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = [tfidf_car1, tfidf_auto1, tfidf_insurance1, tfidf_best1]\n",
    "doc2 = [tfidf_car2, tfidf_auto2, tfidf_insurance2, tfidf_best2]\n",
    "doc3 = [tfidf_car3, tfidf_auto3, tfidf_insurance3, tfidf_best3]\n",
    "\n",
    "for vec in [doc1, doc2, doc3]:\n",
    "  print(np.dot([1,0,1,0], euclidean_normalize(vec)))\n",
    "\n",
    "for vec in [doc1, doc2, doc3]:\n",
    "  print(np.dot([1.65,0,1.62,0], euclidean_normalize(vec)))\n",
    "\n",
    "rank1 = [3,1,2]  # list of numbers from 1,2,3\n",
    "rank2= [3,1,2]\n",
    "\n",
    "\n",
    "rank1,rank2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0V6ZTWjwosSc",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae4c7f3a50552f77bb09474c68497d1e",
     "grade": true,
     "grade_id": "cell-0409ff7b0d9afc0d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(type(rank1),list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdy1KkR7osSd"
   },
   "source": [
    "# Extra theory exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GlmjGyV-osSd",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb1cd8f67689a3d9ed9265539be96d3c",
     "grade": false,
     "grade_id": "isv",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Index size\n",
    "\n",
    "Suppose you have a collection of documents with the following properties:\n",
    "\n",
    "* It has `N` documents.\n",
    "* Each document contains on average `A` many tokens, and `U` many unique tokens.\n",
    "* The vocabulary size of the collection is `V` (this means, that there are `V` many unique words/tokens in the collection.\n",
    "\n",
    "In this question we look at **the size of the posting lists**, when we consider different types of indexes.\n",
    "The size of the posting list is obtained by \"tokenizing\" the posting list. So we ignore separators like comma, and list symbols, etc. For instance, the number of tokens (or the \"length\") of posting `{'d2':(2,[4,18]), 'd8':(1,[7])}` , is 7.\n",
    "\n",
    "Now calculate for each of the following situations the **total number of tokens in the posting lists of the inverted index**.  \n",
    "\n",
    "**For each situation, you should consider the most space efficient index. This means that the index size will grow with each situation described below.**\n",
    "\n",
    "Note the we ask for the size of the posting lists. You do not need to add the space needed for the terms (or termids) themselves.\n",
    "\n",
    "The situations are given in the answer code cell. Give the answer as a formula using the variables declared below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-2zbmHG-osSd",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73ade8444e8c2256af7ca08d24955e28",
     "grade": false,
     "grade_id": "isd",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "N=100 # number of docs\n",
    "V=8000 # number of unique words in collection\n",
    "A=300  # avg number of words per doc\n",
    "U=100  # avg number of unique words per doc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "Iy561zbgosSe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8148a3a0e5f4dffba82a6af7fc3b678e",
     "grade": false,
     "grade_id": "isa",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "a5617c36-8a1c-4714-cd39-24807accea8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# size for an index which is suitable for Boolean search (without any form of ranking)\n",
    "BS_index_size = N * U  \n",
    "\n",
    "\n",
    "print(BS_index_size)\n",
    "\n",
    "# size for an index in which we store for each term  the term-frequency in each document\n",
    "TF_index_size = 2 * N * U \n",
    "\n",
    "print(TF_index_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6u8feOFYosSe",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca776e2d509a6355a875ee5c4268a49e",
     "grade": true,
     "grade_id": "ist",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(BS_index_size,int)\n",
    "\n",
    "# Hier staat een onzichtbare test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "UX8c1lSJosSf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f84f1e4d74fde9b53886f8bcba62678",
     "grade": true,
     "grade_id": "ist-TF",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assert isinstance(TF_index_size,int)\n",
    "# Hier staat een onzichtbare test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "sqdBpWDBosSf",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5acad291cb6bf7d14a318fd6d1fb843",
     "grade": false,
     "grade_id": "is2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Index size 2\n",
    "\n",
    "We continue with the numbers from the previous question and add the following.\n",
    "\n",
    "1. 40% of all unique words in the vocabulary occur only once in the whole collection (so once in one document). These are called _hapaxes_.\n",
    "2. On the other hand  2% of all  unique words in the vocabulary occur in at least half of all documents. We call these terms _stopwords_.\n",
    "\n",
    "Now consider the simplest index from the previous question, which is suitable for Boolean Search.\n",
    "\n",
    "1.  How many tokens are there in the posting lists of the hapaxes? (`Hapax_size`)\n",
    "2.  Minimally how many tokens are there in the posting lists of the stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "KwvXvcYwosSf",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f48b5f3e3b4a3ced6c725006f698382c",
     "grade": false,
     "grade_id": "is2a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "efe714d3-d681-431e-8049-a2136dba2598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400.0\n",
      "16000.0\n"
     ]
    }
   ],
   "source": [
    "# How many tokens are there in the posting lists of the hapaxes?\n",
    "\n",
    "Hapax_size = V * 0.4\n",
    "\n",
    "\n",
    "print(Hapax_size)\n",
    "\n",
    "# Minimally how many tokens are there in the posting lists of the stopwords?\n",
    "Stopword_size = V * 0.02 * 0.5 * N\n",
    "\n",
    "print(Stopword_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "q0NEi-UXosSg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f56d1719be820c8eaa078c4995154807",
     "grade": true,
     "grade_id": "is2t",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(Hapax_size,float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "yXpvG0rzosSg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57abb17510ce630bbf783d931b73fe58",
     "grade": true,
     "grade_id": "is2tbis",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(Stopword_size,float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "eaKc0pEZosSg",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d49bc59fb629d3c3bd8f187c8c17420",
     "grade": false,
     "grade_id": "cell-0d69e1c149fbb6d7",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Programming (Inverted Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "70e_Ob8rosSg",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e0ac826e7f460ca7197f3e187bd993d",
     "grade": false,
     "grade_id": "cell-6a3911454d0b8cb2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict,Counter,defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import itertools\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm_notebook\n",
    "import nltk\n",
    "import zipfile\n",
    "import math\n",
    "import numpy as np\n",
    "def loadShakespeare():\n",
    "    if 'shaks200.zip' in os.listdir():\n",
    "        return 'shaks200.zip'\n",
    "    elif os.path.exists('../../data/Week1/'):\n",
    "        return '../../data/Week1/shaks200.zip'\n",
    "    elif os.path.exists('../../../data/Week1/'):\n",
    "        return '../../../data/Week1/shaks200.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUXFUryFosSh",
    "outputId": "a0a673aa-81f5-4c25-9b1a-677b9ee61f7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zipfile.ZipFile filename='shaks200.zip' mode='r'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipfile.ZipFile('shaks200.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "cc68332c6c1f4bd2a41c14a09f89a992",
      "992501c04d904950968259b8a4c76fc3",
      "d97973ec2e4f4beb8b4d05a457810e03",
      "00a5c903a7ba4ddd931f7ca0295e4591",
      "fac83ffb907e407ba4fc6e7ef41b7f83",
      "961372e8d5c141a09e46f52839936caa",
      "62c92adcb6e240cd86690551aa376bd4",
      "d108e8a840744afebfd05fc29ad71950",
      "d0511fbfa1fa4efe8fbc36c5398e7a68",
      "de64a100faeb4f99bb85c1aa7ebd2d5f",
      "b6517745f1724a83b5ae93e1070faa98"
     ]
    },
    "deletable": false,
    "id": "oPq5JBB0osSh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b79be685015b3e1f2523bc94fa07165",
     "grade": false,
     "grade_id": "cell-512011c182747803",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "72c579c5-cd17-4f88-fa79-a7ded41351b1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc68332c6c1f4bd2a41c14a09f89a992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 157 ms, total: 16.3 s\n",
      "Wall time: 16.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(defaultdict(int,\n",
       "             {'a_and_c': 875,\n",
       "              'all_well': 736,\n",
       "              'as_you': 698,\n",
       "              'com_err': 445,\n",
       "              'coriolan': 1130,\n",
       "              'cymbelin': 973,\n",
       "              'dream': 565,\n",
       "              'hamlet': 1146,\n",
       "              'hen_iv_1': 869,\n",
       "              'hen_iv_2': 1001,\n",
       "              'hen_v': 1089,\n",
       "              'hen_vi_1': 732,\n",
       "              'hen_vi_2': 953,\n",
       "              'hen_vi_3': 818,\n",
       "              'hen_viii': 950,\n",
       "              'j_caesar': 615,\n",
       "              'john': 734,\n",
       "              'lear': 911,\n",
       "              'lll': 861,\n",
       "              'm_for_m': 702,\n",
       "              'm_wives': 611,\n",
       "              'macbeth': 736,\n",
       "              'merchant': 841,\n",
       "              'much_ado': 581,\n",
       "              'othello': 765,\n",
       "              'pericles': 635,\n",
       "              'r_and_j': 687,\n",
       "              'rich_ii': 752,\n",
       "              'rich_iii': 995,\n",
       "              't_night': 552,\n",
       "              'taming': 512,\n",
       "              'tempest': 522,\n",
       "              'timon': 510,\n",
       "              'titus': 659,\n",
       "              'troilus': 846,\n",
       "              'two_gent': 410,\n",
       "              'win_tale': 861}),\n",
       " defaultdict(int,\n",
       "             {'a_and_c': 3,\n",
       "              'com_err': 3,\n",
       "              'cymbelin': 1,\n",
       "              'hamlet': 1,\n",
       "              'hen_iv_1': 1,\n",
       "              'hen_v': 1,\n",
       "              'hen_vi_1': 3,\n",
       "              'hen_vi_2': 6,\n",
       "              'hen_vi_3': 1,\n",
       "              'lear': 1,\n",
       "              'm_wives': 9,\n",
       "              'macbeth': 52,\n",
       "              'much_ado': 1,\n",
       "              'rich_iii': 2,\n",
       "              'tempest': 3,\n",
       "              'timon': 1,\n",
       "              'troilus': 2,\n",
       "              'win_tale': 1}))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "def index_collection(zipfolder):\n",
    "    # With zipfile we can read the file without opening the zip file\n",
    "    archive = zipfile.ZipFile(zipfolder, 'r')\n",
    "    namelist = [x for x in archive.namelist() if '.xml' in x]\n",
    "    MyIndex = defaultdict(lambda: defaultdict(int)) # initialize MyIndex\n",
    "    for infile in tqdm_notebook(namelist): # loop over each file\n",
    "        f = archive.open(infile)\n",
    "        txt = BeautifulSoup(f).get_text()\n",
    "        txt = txt.lower()\n",
    "        tokenized = nltk.word_tokenize(txt)\n",
    "        tokenized = [word for word in tokenized if word.isalpha()]\n",
    "        for word in tokenized:\n",
    "            MyIndex[word][infile[:-4]] += 1\n",
    "                \n",
    "    return MyIndex\n",
    "\n",
    "%time Shakespeare = index_collection(loadShakespeare())\n",
    "\n",
    "Shakespeare['the'], Shakespeare['witch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "5PrxRK7yosSh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43e99aef339cc287e8b41581bf07b8a8",
     "grade": false,
     "grade_id": "cell-512011c182747803a",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "dec3a683-9682-42a2-e374-19160baa9ea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CorpusFreq': 28278,\n",
       " 'DocFreq': 37,\n",
       " 'Freq_per_Doc': defaultdict(int,\n",
       "             {'a_and_c': 875,\n",
       "              'all_well': 736,\n",
       "              'as_you': 698,\n",
       "              'com_err': 445,\n",
       "              'coriolan': 1130,\n",
       "              'cymbelin': 973,\n",
       "              'dream': 565,\n",
       "              'hamlet': 1146,\n",
       "              'hen_iv_1': 869,\n",
       "              'hen_iv_2': 1001,\n",
       "              'hen_v': 1089,\n",
       "              'hen_vi_1': 732,\n",
       "              'hen_vi_2': 953,\n",
       "              'hen_vi_3': 818,\n",
       "              'hen_viii': 950,\n",
       "              'j_caesar': 615,\n",
       "              'john': 734,\n",
       "              'lear': 911,\n",
       "              'lll': 861,\n",
       "              'm_for_m': 702,\n",
       "              'm_wives': 611,\n",
       "              'macbeth': 736,\n",
       "              'merchant': 841,\n",
       "              'much_ado': 581,\n",
       "              'othello': 765,\n",
       "              'pericles': 635,\n",
       "              'r_and_j': 687,\n",
       "              'rich_ii': 752,\n",
       "              'rich_iii': 995,\n",
       "              't_night': 552,\n",
       "              'taming': 512,\n",
       "              'tempest': 522,\n",
       "              'timon': 510,\n",
       "              'titus': 659,\n",
       "              'troilus': 846,\n",
       "              'two_gent': 410,\n",
       "              'win_tale': 861})}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Copy your answers to question 3 from week 1 here,\n",
    "So NewIndex will be created\"\"\"\n",
    "CorpusFreq = {wrd : sum(Shakespeare[wrd].values()) for wrd in Shakespeare} # change to your solution\n",
    "DocFreq = {wrd : len(Shakespeare[wrd].values()) for wrd in Shakespeare} # change to your solution\n",
    "NewIndex = {wrd : {'CorpusFreq' : CorpusFreq[wrd],\n",
    "                   'DocFreq' : DocFreq[wrd],\n",
    "                   'Freq_per_Doc' : Shakespeare[wrd]} for wrd in Shakespeare} # change to your solution\n",
    "\n",
    "NewIndex['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "deletable": false,
    "id": "Bfrg7cM7osSh",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93809a2f0574d236d7cab7af05633ec2",
     "grade": false,
     "grade_id": "cell-512011c182747803b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Copy your answers to question 3 from week 1 here,\n",
    "So NewIndex[\"TotalFiles\"] will be created\"\"\"\n",
    "\n",
    "NewIndex[\"TotalFiles\"] = 37 # I'm not sure if this is what they want here...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "mFOp7JNnosSj"
   },
   "outputs": [],
   "source": [
    "# test the schema of NewIndex. For each term, these attributes should be present.\n",
    "assert_equal(set(NewIndex['the'].keys()), {'Freq_per_Doc', 'CorpusFreq', 'DocFreq'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "FoInSHShosSj",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48fb5012e4a15ab1395c196363e05e87",
     "grade": true,
     "grade_id": "cell-0a422d512c7a3d0f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(NewIndex) > 1\n",
    "assert_equal(type(NewIndex[\"TotalFiles\"]), int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KbKdJEksosSk",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e553307753361672a9936ae48fa9189c",
     "grade": false,
     "grade_id": "cell-ce0992093a8a8c20",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 9 Ranked Retrieval\n",
    "\n",
    "In this section we extend the boolean search engine to perform more sophisticated ranked retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "MqcsYiUAosSk",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1502eea27a546b5195aebe932b56e5d",
     "grade": false,
     "grade_id": "cell-9c893a10d347de93",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 9.1 TF-IDF\n",
    "Implement the TF-IDF function 6.8 from the IR -book. So, given a query term $t$ and a document $d$, compute and return the tf-idf$_{t,d}$ score.\n",
    "\n",
    "Note that we use the raw term frequency here, as in the book. Not the log normalized tf as in the slides.\n",
    "\n",
    "**Use logarithm with base 2 in this and all further exercises.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "hSSaHeososSk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8499b76c9641d46097b0e0a2b721761",
     "grade": false,
     "grade_id": "cell-0a466ded8aed5c5c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "c8391b8b-b1c0-4414-a9be-bf43d2a6e8e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6283600968868495"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf(term, document, index):\n",
    "    \"\"\"\n",
    "    Given a single query term and a document, score the document using\n",
    "    tf-idf.\n",
    "    \"\"\"\n",
    "    if index[term]['Freq_per_Doc'][document] > 0:\n",
    "        tf = 1 + np.log2(index[term]['Freq_per_Doc'][document])\n",
    "    else:\n",
    "        tf = 0\n",
    "    idf = np.log2(index['TotalFiles'] / index[term]['DocFreq'])\n",
    "    return tf * idf\n",
    "    \n",
    "tfidf('brutus', 'a_and_c', NewIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "g2zTUOwrosSk",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec659575841200d6971c94f78434d4a5",
     "grade": true,
     "grade_id": "cell-e35bc40f7ab55f2f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(tfidf('brutus', 'a_and_c', NewIndex), float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "KV22Hi7AosSk",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a63208b13a56a27ae1fc6ac6922c6b13",
     "grade": false,
     "grade_id": "cell-167e8d7be386a82e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 9.2 TF-IDF Ranked Search\n",
    "\n",
    "Implement the scoring function 6.9 from the IR -book. So, given a query $Q$ consisting of a list of words, compute for each document the score for this query, and return the document ids and scores in decreasing order.\n",
    "\n",
    "Break ties alphabettically on the doc id (so if docs a and b have the same score a should appear before b).\n",
    "\n",
    "The result is a list of pairs ('docid','score')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "vRSSjNwvosSl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fd7877e511fdb0a0af3a38006e96220",
     "grade": false,
     "grade_id": "cell-966e28b929230aab",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "c45fb47d-fa23-423b-a17e-69772d74f445"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('j_caesar', 29.912136931137667),\n",
       " ('coriolan', 17.16344100120443),\n",
       " ('a_and_c', 15.4502883324907),\n",
       " ('cymbelin', 4.9710165427462405),\n",
       " ('hamlet', 4.132505069999678),\n",
       " ('hen_vi_2', 4.132505069999678),\n",
       " ('titus', 3.170979217814314),\n",
       " ('hen_v', 3.170979217814314),\n",
       " ('rich_iii', 2.884577556556093),\n",
       " ('merchant', 2.2094533656289497),\n",
       " ('m_for_m', 1.9230517043707287),\n",
       " ('hen_vi_1', 1.9230517043707287),\n",
       " ('hen_vi_3', 1.9230517043707287),\n",
       " ('all_well', 0.9615258521853643),\n",
       " ('as_you', 0.9615258521853643),\n",
       " ('hen_iv_2', 0.9615258521853643),\n",
       " ('lll', 0.9615258521853643),\n",
       " ('m_wives', 0.9615258521853643),\n",
       " ('macbeth', 0.9615258521853643),\n",
       " ('othello', 0.9615258521853643),\n",
       " ('rich_ii', 0.9615258521853643),\n",
       " ('john', 0.0),\n",
       " ('hen_viii', 0.0),\n",
       " ('much_ado', 0.0),\n",
       " ('lear', 0.0),\n",
       " ('pericles', 0.0),\n",
       " ('r_and_j', 0.0),\n",
       " ('two_gent', 0.0),\n",
       " ('hen_iv_1', 0.0),\n",
       " ('t_night', 0.0),\n",
       " ('dream', 0.0),\n",
       " ('taming', 0.0),\n",
       " ('tempest', 0.0),\n",
       " ('com_err', 0.0),\n",
       " ('timon', 0.0),\n",
       " ('troilus', 0.0),\n",
       " ('win_tale', 0.0)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rankedSearchTfidf(query,index):\n",
    "    \"\"\"\n",
    "    Given a query, score the documents according to the tf-idf scoring\n",
    "    scheme and return  the documents and scores in decreasing order.\n",
    "    Break ties alphabettically on the doc id (so if docs a and b have the same score a should appear before b)\n",
    "    \"\"\"\n",
    "#     Get all docids in alphabetical order\n",
    "    docids = set()\n",
    "    TotalFiles = index['TotalFiles']\n",
    "    for token in index.keys():\n",
    "        docids = docids.union(set(index[token]['Freq_per_Doc'].keys()))\n",
    "        if len(docids) == TotalFiles:\n",
    "            break\n",
    "    docids = sorted(docids)\n",
    "#     Compute overlap score measure for every document\n",
    "    scores = []\n",
    "    for document in docids:\n",
    "        score = 0\n",
    "        for term in query:\n",
    "            score += tfidf(term, document, index)\n",
    "        scores.append((document, score))\n",
    "\n",
    "#     Order by score\n",
    "    scores_ordered = np.array(scores)[np.argsort(np.array([elem[1] for elem in scores]))][::-1]\n",
    "#     Convert ordered scores to list of tuples\n",
    "    return [(str(l[0]), float(l[1])) for l in scores_ordered]\n",
    "\n",
    "\n",
    "rankedSearchTfidf(['brutus', 'caesar'], NewIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "C6h-XnIgosSl",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0fb1eb12ec132a8c00e05c5b1cf1b6e",
     "grade": true,
     "grade_id": "cell-1ca47df9d70de0ed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result = rankedSearchTfidf(['brutus','caesar'], NewIndex)\n",
    "assert_equal(type(result),list)\n",
    "assert_equal(type(result[0]),tuple)\n",
    "assert_equal(type(result[0][0]),str)\n",
    "assert isinstance(result[0][1],float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j24B88TmosSm",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85a361c8618ed3f3b187af5e32c4dc5f",
     "grade": false,
     "grade_id": "cell-46fab5262171c652",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 9.3 Vector Space Model\n",
    "\n",
    "We now want to implement the cosine similarity function. To do this we need to vectorize documents and normalize them. We use Euclidean length for that (see section 6.3). Create a function that can vectorize and normalize a document:\n",
    "\n",
    "$normalizedVector(d) = \\frac{V(d)}{|V(d)|}$\n",
    "\n",
    "* Make sure you don't take `TotalFiles` as a word\n",
    "* Include all words in the corpus, even if they are not in document (so they will be 0)\n",
    "* Make sure you sort the words alphabetically\n",
    "* the value for each term is its TF-IDF weight as calculated by your earlier `tfidf` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "-8go_8_xosSm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71013f66dc1212be5cc0a4f483e9d10a",
     "grade": false,
     "grade_id": "cell-c9694a0ad4a895c6",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "f07f54f7-5e4a-46f6-f1e8-db7243962ef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22327 [0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def normalizedVector(document, index):\n",
    "    \"\"\"\n",
    "    Given a document, vectorize and normalize it\n",
    "    \"\"\"\n",
    "#     Vectorize document using tf-idf weighting scheme to compute components\n",
    "    vector = []\n",
    "    for token in list(NewIndex.keys())[:-1]:\n",
    "        vector.append(tfidf(token, document, index))\n",
    "#     Return normalized vector\n",
    "    return euclidean_normalize(vector)\n",
    "    \n",
    "print(len(normalizedVector('all_well', NewIndex)), normalizedVector('all_well', NewIndex)[:5])\n",
    "# Check that the Euclidean length of your vector equals 1\n",
    "assert_almost_equal(1., np.sqrt(np.sum(np.array(normalizedVector('all_well', NewIndex))**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "hXXUjquRosSm",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "401805946e2c5af0a0a2ede6f43bbc1e",
     "grade": true,
     "grade_id": "cell-2e8497964ac87a83",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(len(normalizedVector('all_well', NewIndex)), len(NewIndex)-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "5SvM8sJdosSn",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "022cc4171dc22326a8ad75e66d323bf3",
     "grade": false,
     "grade_id": "cell-bc303ce875aa2bcf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 9.4 Cosine Similarity\n",
    "\n",
    "Use the normalized lengths to compute the cosine-similarity between a query and a document. I.e. implement scoring formula 6.12 from the book.\n",
    "\n",
    "Do this in the form of the function `cosineSimilarity(query, document, index)`\n",
    "\n",
    "The query vector is a boolean vector with the value for a term being 1 if and only if it occurs at least once in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "X8yZwdgdosSn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8138b0030c003559ec4bbbf63ffa07f5",
     "grade": false,
     "grade_id": "cell-a87cb124f00cdf2e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "4bb83c34-bb11-4979-9ccf-16cbd0859e9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006385730632023845"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosineSimilarity(query, document, index):\n",
    "    \"\"\"\n",
    "    Given a query and a document, compute and return the cosine-similarity\n",
    "    between the two.\n",
    "    \"\"\"\n",
    "#     Vectorize query and normalize\n",
    "    vocab = sorted(list(index.keys())[:-1])\n",
    "    query_vector = [0 for i in range(len(vocab))]\n",
    "    for q in query:\n",
    "        query_vector[vocab.index(q)] += 1\n",
    "    query_vector = euclidean_normalize(query_vector)\n",
    "#     return dot product of normed doc and query vector\n",
    "    doc_vector = normalizedVector(document, index)\n",
    "    return np.dot(doc_vector, query_vector)\n",
    "    \n",
    "cosineSimilarity(['brutus','love'], 'a_and_c', NewIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qm-JOuC7osSn",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3303339d40025d69d7d04f4fb7e26a2",
     "grade": true,
     "grade_id": "cell-c960058b3d6d3183",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(cosineSimilarity(['love','lightly'], 'all_well', NewIndex)) in [float, np.float64, np.float32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "vxdwz2WUosSo",
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22bfcf588c705a82d7e07222d84759e2",
     "grade": false,
     "grade_id": "cell-9c5c306eae897889",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 9.5 Okapi BM25\n",
    "Now create a search engine which scores according to another famous scoring formula [Okapi BM25](https://en.wikipedia.org/wiki/Okapi_BM25)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deletable": false,
    "id": "cCNNkI_tosSo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a543ac97d16ad6fa14d1bdc3046bc3ba",
     "grade": false,
     "grade_id": "cell-236a53b720ae81a9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "outputId": "b7777dbe-b42e-4cad-8636-b33019294ba4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('j_caesar', 4.838594700078149),\n",
       " ('coriolan', 4.509884620424414),\n",
       " ('a_and_c', 3.5720123933675154),\n",
       " ('titus', 2.3022258989548936),\n",
       " ('merchant', 2.2826470570356086),\n",
       " ('hen_vi_2', 2.094659839691316),\n",
       " ('hen_v', 2.071159883099632),\n",
       " ('hamlet', 1.915864489203865),\n",
       " ('as_you', 0.0),\n",
       " ('com_err', 0.0),\n",
       " ('all_well', 0.0),\n",
       " ('cymbelin', 0.0),\n",
       " ('dream', 0.0),\n",
       " ('john', 0.0),\n",
       " ('hen_iv_1', 0.0),\n",
       " ('hen_iv_2', 0.0),\n",
       " ('hen_vi_1', 0.0),\n",
       " ('hen_vi_3', 0.0),\n",
       " ('hen_viii', 0.0),\n",
       " ('win_tale', 0.0),\n",
       " ('lear', 0.0),\n",
       " ('rich_ii', 0.0),\n",
       " ('troilus', 0.0),\n",
       " ('timon', 0.0),\n",
       " ('tempest', 0.0),\n",
       " ('taming', 0.0),\n",
       " ('t_night', 0.0),\n",
       " ('rich_iii', 0.0),\n",
       " ('r_and_j', 0.0),\n",
       " ('two_gent', 0.0),\n",
       " ('pericles', 0.0),\n",
       " ('othello', 0.0),\n",
       " ('much_ado', 0.0),\n",
       " ('macbeth', 0.0),\n",
       " ('m_wives', 0.0),\n",
       " ('m_for_m', 0.0),\n",
       " ('lll', 0.0)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rankedSearchBM25(query, index, a=1.5, b=0.75):\n",
    "    \"\"\"\n",
    "    Given a query, score the documents according to the BM25 scoring\n",
    "    scheme and return a list of  (document, score) pairs  in decreasing order\n",
    "    \"\"\"\n",
    "#     Get all docids in alphabetical order\n",
    "    docids = set()\n",
    "    TotalFiles = index['TotalFiles']\n",
    "    for token in index.keys():\n",
    "        docids = docids.union(set(index[token]['Freq_per_Doc'].keys()))\n",
    "        if len(docids) == TotalFiles:\n",
    "            break\n",
    "    docids = sorted(docids)\n",
    "\n",
    "#     Get word count per document and average document length\n",
    "    word_count = Counter()\n",
    "    for token in list(index.keys())[:-1]:\n",
    "        word_count += Counter(index[token]['Freq_per_Doc'])\n",
    "    avgdl = sum(word_count.values()) / TotalFiles\n",
    "\n",
    "#     Compute BM25 score of query per document\n",
    "    scores = []\n",
    "    for document in docids:\n",
    "        score = 0\n",
    "        for term in query:\n",
    "            if index[term]['Freq_per_Doc'][document] > 0:\n",
    "                tf = 1 + np.log2(index[term]['Freq_per_Doc'][document])\n",
    "            else:\n",
    "                tf = 0\n",
    "            idf = np.log2(index['TotalFiles'] / index[term]['DocFreq'])\n",
    "            score += idf * (tf * (a + 1) / (tf + a * (1 - b + b * word_count[document] / avgdl)))\n",
    "        scores.append((document, score))\n",
    "\n",
    "#     Order by score\n",
    "    scores_ordered = np.array(scores)[np.argsort(np.array([elem[1] for elem in scores]))][::-1]\n",
    "#     Convert ordered scores to list of tuples\n",
    "    return [(str(l[0]), float(l[1])) for l in scores_ordered]\n",
    "    \n",
    "rankedSearchBM25(['brutus'], NewIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "RpyMKdd9osSo",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "096ddb7cfd35f4291a2b3a2edaca9889",
     "grade": true,
     "grade_id": "cell-860fbb8c8bd77a2a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "result = rankedSearchBM25(['brutus'], NewIndex)\n",
    "assert_equal(type(result),list)\n",
    "assert_equal(type(result[0]),tuple)\n",
    "assert_equal(type(result[0][0]),str)\n",
    "assert isinstance(result[0][1],float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "mSOGCuRPosSo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ryikBztNosSZ"
   ],
   "name": "AssignmentWeek2.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00a5c903a7ba4ddd931f7ca0295e4591": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0511fbfa1fa4efe8fbc36c5398e7a68",
      "max": 37,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d108e8a840744afebfd05fc29ad71950",
      "value": 37
     }
    },
    "62c92adcb6e240cd86690551aa376bd4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "961372e8d5c141a09e46f52839936caa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "992501c04d904950968259b8a4c76fc3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6517745f1724a83b5ae93e1070faa98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc68332c6c1f4bd2a41c14a09f89a992": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d97973ec2e4f4beb8b4d05a457810e03",
       "IPY_MODEL_00a5c903a7ba4ddd931f7ca0295e4591",
       "IPY_MODEL_fac83ffb907e407ba4fc6e7ef41b7f83"
      ],
      "layout": "IPY_MODEL_992501c04d904950968259b8a4c76fc3"
     }
    },
    "d0511fbfa1fa4efe8fbc36c5398e7a68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d108e8a840744afebfd05fc29ad71950": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d97973ec2e4f4beb8b4d05a457810e03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_62c92adcb6e240cd86690551aa376bd4",
      "placeholder": "​",
      "style": "IPY_MODEL_961372e8d5c141a09e46f52839936caa",
      "value": "100%"
     }
    },
    "de64a100faeb4f99bb85c1aa7ebd2d5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fac83ffb907e407ba4fc6e7ef41b7f83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b6517745f1724a83b5ae93e1070faa98",
      "placeholder": "​",
      "style": "IPY_MODEL_de64a100faeb4f99bb85c1aa7ebd2d5f",
      "value": " 37/37 [00:16&lt;00:00,  2.46it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
